{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "# enable absolute paths transversal (from notebooks folder to src folder)\n",
    "parent_dir = os.path.abspath('..')\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "    \n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from pypfopt import expected_returns, EfficientFrontier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import src.utils as utils\n",
    "import src.macro.calculate as calculate\n",
    "import src.macro.plot as plot\n",
    "\n",
    "tickers = ['AAPL','AMZN','NVDA','MMC','GOOG','MSFT','BTC-USD','ETH-USD','XOM','BAC','V','GOLD','^GSPC']\n",
    "start_date = '2010-01-01'\n",
    "end_date = datetime.now() - timedelta(1)\n",
    "\n",
    "# just grabbing the 'Adj Close' column\n",
    "stock_data = utils.get_stock_data(tickers, start_date, end_date)\n",
    "\n",
    "sp500_data = stock_data['^GSPC']\n",
    "stock_data = stock_data.drop(['^GSPC'], axis=1)\n",
    "\n",
    "stock_data.tail()\n",
    "\n",
    "\"\"\"similar to portfolio/display.py, set the portfolio weights and calculate the performance\n",
    "\"\"\"\n",
    "risk_free_rate = 0.04\n",
    "mu = expected_returns.mean_historical_return(stock_data)\n",
    "S = utils.calculate_covariance_matrix(stock_data)\n",
    "\n",
    "# Calculating the cumulative monthly returns of a portfolio of stocks with given weights:\n",
    "min_risk, max_risk = utils.calculate_risk_extents(mu, S, risk_free_rate)\n",
    "risk = (max_risk + min_risk) / 2\n",
    "\n",
    "ef = EfficientFrontier(mu, S)\n",
    "ef.efficient_risk(risk)\n",
    "weights = ef.clean_weights()\n",
    "weights = pd.Series(weights).reindex(stock_data.columns)\n",
    "ef_returns, ef_volatility, ef_sharpe = ef.portfolio_performance(risk_free_rate)\n",
    "print(f'ef weights:\\n{weights}')\n",
    "print(f'ef performance: {ef_returns, ef_volatility, ef_sharpe}')\n",
    "\n",
    "\n",
    "daily_returns = stock_data.pct_change()\n",
    "weighted_daily_returns = daily_returns.mul(weights, axis=1)\n",
    "portfolio_daily_returns = weighted_daily_returns.sum(axis=1)\n",
    "portfolio_monthly_returns = portfolio_daily_returns.resample('M').apply(lambda x: (1 + x).prod() - 1).dropna()\n",
    "portfolio_quarterly_returns = portfolio_daily_returns.resample('Q').apply(lambda x: (1 + x).prod() - 1).dropna()\n",
    "portfolio_annual_returns = portfolio_daily_returns.resample('Y').apply(lambda x: (1 + x).prod() - 1).dropna()\n",
    "\n",
    "portfolio_cumulative_daily_returns = ((1 + portfolio_daily_returns).cumprod() - 1).dropna()\n",
    "portfolio_cumulative_monthly_returns = ((1 + portfolio_monthly_returns).cumprod() - 1).dropna()\n",
    "portfolio_cumulative_quarterly_returns = ((1 + portfolio_quarterly_returns).cumprod() - 1).dropna()\n",
    "portfolio_cumulative_annual_returns = ((1 + portfolio_annual_returns).cumprod() - 1).dropna()\n",
    "\n",
    "sp500_daily_returns = sp500_data.pct_change()\n",
    "sp500_monthly_returns = sp500_daily_returns.resample('M').apply(lambda x: (1 + x).prod() - 1).dropna()\n",
    "sp500_quarterly_returns = sp500_daily_returns.resample('Q').apply(lambda x: (1 + x).prod() - 1).dropna()\n",
    "sp500_annual_returns = sp500_daily_returns.resample('Y').apply(lambda x: (1 + x).prod() - 1).dropna()\n",
    "\n",
    "sp500_cumulative_daily_returns = ((1 + sp500_daily_returns).cumprod() - 1).dropna()\n",
    "sp500_cumulative_monthly_returns = ((1 + sp500_monthly_returns).cumprod() - 1).dropna()\n",
    "sp500_cumulative_quarterly_returns = ((1 + sp500_quarterly_returns).cumprod() - 1).dropna()\n",
    "sp500_cumulative_annual_returns = ((1 + sp500_annual_returns).cumprod() - 1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat this for the S&P500\n",
    "import os, sys\n",
    "parent_dir = os.path.abspath('..')\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "    \n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from pypfopt import expected_returns, EfficientFrontier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objs as go\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import src.utils as utils\n",
    "import src.macro.calculate as calculate\n",
    "import src.macro.plot as plot\n",
    "\n",
    "\n",
    "# need a plotting function that takes in the portfolio, benchmark, and macroeconomic data and plots them all together\n",
    "# need to be able to specify the time period (monthly, quarterly, annual) and loop over the factors\n",
    "def plot_portfolio_vs_benchmark_vs_macro(portfolio_returns, benchmark_returns, macro_time_series, time_period, title_prefix=''):\n",
    "    \"\"\"Plot the portfolio returns vs the benchmark returns vs the macroeconomic data\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    portfolio_returns : pandas.Series\n",
    "        The portfolio returns\n",
    "    benchmark_returns : pandas.Series\n",
    "        The benchmark returns\n",
    "    macro_data_dict : dict\n",
    "        A dictionary containing the macroeconomic data\n",
    "    macro_time_series_name : str\n",
    "        The name of the macroeconomic time series\n",
    "    time_period : str\n",
    "        The time period to plot the data for (monthly, quarterly, or annual)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Create subplot for each macro factor\n",
    "    for factor, macro_factor_series in macro_time_series.items():\n",
    "\n",
    "        # Create a subplot with two y-axes\n",
    "        fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "        # Add S&P500 return trace\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=benchmark_returns.index, y=benchmark_returns, mode='lines', name='S&P500 Returns'),\n",
    "            secondary_y=False,\n",
    "        )\n",
    "        \n",
    "        # Add portfolio return trace\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=portfolio_returns.index, y=portfolio_returns, mode='lines', name='Weighted Portfolio Returns', line=dict(color='royalblue')),\n",
    "            secondary_y=False,\n",
    "        )\n",
    "\n",
    "        # Add macroeconomic factor trace\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=macro_factor_series.index, y=macro_factor_series, mode='lines', name=factor, line=dict(dash='dot')),\n",
    "            secondary_y=True\n",
    "        )\n",
    "\n",
    "        # Set axis titles\n",
    "        #fig.update_xaxes(title_text=\"Date\")\n",
    "        fig.update_yaxes(title_text=\"Returns %\", secondary_y=False, tickformat=\".1%\")\n",
    "        \n",
    "        if 'Change' in factor or 'Rate' in factor:\n",
    "            fig.update_yaxes(title_text=f'{factor} %', secondary_y=True, tickformat=\".1%\")\n",
    "        else:\n",
    "            fig.update_yaxes(title_text=factor, secondary_y=True)\n",
    "\n",
    "        # Set title\n",
    "        fig.update_layout(title_text=f'{title_prefix}Weighted Portfolio vs {title_prefix}S&P500 Returns vs {factor}<br><sup>Time Period: {time_period}</sup>')\n",
    "        \n",
    "        fig.show()\n",
    "               \n",
    "def plot_portfolio_vs_benchmark_vs_macro_altair(dict_of_dict_returns, dict_of_dict_cumulative_returns):\n",
    "    # Define the list of time periods\n",
    "    time_periods = ['Monthly', 'Quarterly', 'Yearly']\n",
    "\n",
    "    # Iterate over the time periods\n",
    "    for period in time_periods:\n",
    "        returns = dict_of_dict_returns[period]\n",
    "        cumulative_returns = dict_of_dict_cumulative_returns[period]\n",
    "        \n",
    "        # Iterate over the macro factors\n",
    "        for factor in returns['Macro']:\n",
    "            # Create a DataFrame for Altair\n",
    "            df = pd.DataFrame({\n",
    "                'Date': returns['Portfolio'].index,\n",
    "                f'{period} Portfolio Returns': returns['Portfolio'].values,\n",
    "                f'{period} S&P500 Returns': returns['S&P500'].values,\n",
    "                f'{period} {factor}': returns['Macro'][factor].values,\n",
    "                f'Cumulative {period} Portfolio Returns': cumulative_returns['Portfolio'].values,\n",
    "                f'Cumulative {period} S&P500 Returns': cumulative_returns['S&P500'].values,\n",
    "                f'Cumulative {period} {factor}': cumulative_returns['Macro'][factor].values,\n",
    "            })\n",
    "\n",
    "            # Make the Altair chart for returns\n",
    "            chart_returns = alt.Chart(df).transform_fold(\n",
    "                [f'{period} Portfolio Returns', f'{period} S&P500 Returns', f'{period} {factor}']\n",
    "            ).mark_line().encode(\n",
    "                x='Date:T',\n",
    "                y=alt.Y('value:Q', title='Returns'),\n",
    "                color='key:N'\n",
    "            ).properties(\n",
    "                title=f'{factor} - {period} Returns'\n",
    "            )\n",
    "\n",
    "            # Make the Altair chart for cumulative returns\n",
    "            chart_cumulative_returns = alt.Chart(df).transform_fold(\n",
    "                [f'Cumulative {period} Portfolio Returns', f'Cumulative {period} S&P500 Returns', f'Cumulative {period} {factor}']\n",
    "            ).mark_line().encode(\n",
    "                x='Date:T',\n",
    "                y=alt.Y('value:Q', title='Cumulative Returns'),\n",
    "                color='key:N'\n",
    "            ).properties(\n",
    "                title=f'{factor} - Cumulative {period} Returns'\n",
    "            )\n",
    "\n",
    "            # Display the charts\n",
    "            chart_returns.display()\n",
    "            chart_cumulative_returns.display()\n",
    "                \n",
    "# macro_data_dict = {'Macro Factor Name': has a dictionary with time series of the factor values\n",
    "#        'Monthly': monthly_mean, -> compare this with *cumulative* monthly returns\n",
    "#        'Monthly Change': -> monthly_change, compare this with monthly returns\n",
    "#        'Quarterly': -> quarterly_mean, compare this with *cumulative* quarterly returns\n",
    "#        'Quarterly -> Change': quarterly_change, compare this with quarterly returns \n",
    "#        'Yearly': -> yearly_mean, compare this with *cumulative* annual returns\n",
    "#        'Yearly Change': -> yearly_change compare this with annual returns\n",
    "\n",
    "start_date = '2010-01-01'\n",
    "end_date = datetime.now() - timedelta(1)\n",
    "\n",
    "macro_data_dict = calculate.get_historical_macro_data(start_date, end_date)\n",
    "\n",
    "monthly_macro_data = {}\n",
    "mom_change_in_macro_data = {}\n",
    "\n",
    "quarterly_macro_data = {}\n",
    "qoq_change_in_macro_data = {}\n",
    "\n",
    "yearly_macro_data = {}\n",
    "yoy_change_in_macro_data = {}\n",
    "\n",
    "# parse the macro data dictionary into monthly, quarterly, and yearly data for comparison with the portfolio returns\n",
    "for factor, time_bases in macro_data_dict.items():\n",
    "    for time_basis, time_series in time_bases.items():\n",
    "        if time_basis == 'Monthly':\n",
    "            monthly_macro_data[factor] = time_series.dropna()\n",
    "            \n",
    "        if time_basis == 'Monthly Change': \n",
    "            mom_change_in_macro_data[factor] = time_series.dropna()\n",
    "            \n",
    "        if time_basis == 'Quarterly':\n",
    "            quarterly_macro_data[factor] = time_series.dropna()\n",
    "            \n",
    "        if time_basis == 'Quarterly Change':\n",
    "            qoq_change_in_macro_data[factor] = time_series.dropna()\n",
    "            \n",
    "        if time_basis == 'Yearly':\n",
    "            yearly_macro_data[factor] = time_series.dropna()\n",
    "        \n",
    "        if time_basis == 'Yearly Change':\n",
    "            yoy_change_in_macro_data[factor] = time_series.dropna()\n",
    "            \n",
    "def merge_dataframes(df_dict):\n",
    "    # Start by merging the 'Portfolio' and 'S&P500' DataFrames\n",
    "    portfolio_df = pd.DataFrame(df_dict['Portfolio'], columns=['Portfolio'])\n",
    "    sp500_df = pd.DataFrame(df_dict['S&P500'], columns=['S&P500'])\n",
    "    merged_df = portfolio_df.merge(sp500_df, left_index=True, right_index=True, how='inner')\n",
    "\n",
    "    # Then, merge each macro factor DataFrame into the merged DataFrame\n",
    "    macro_df_dict = df_dict['Macro']\n",
    "    for factor in macro_df_dict:\n",
    "        factor_df = pd.DataFrame(macro_df_dict[factor], columns=[factor])\n",
    "        merged_df = merged_df.merge(factor_df, left_index=True, right_index=True, how='inner')\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "def dict_to_combined_dict_of_df(monthly_dict, quarterly_dict, yearly_dict):\n",
    "    # Merge data for each time period and return type\n",
    "    merged_monthly_returns = merge_dataframes(monthly_dict)\n",
    "    merged_quarterly_returns = merge_dataframes(quarterly_dict)\n",
    "    merged_annual_returns = merge_dataframes(yearly_dict)\n",
    "\n",
    "    # Store merged data in the original data structures\n",
    "    returns_data = {\n",
    "        'Monthly': merged_monthly_returns,\n",
    "        'Quarterly': merged_quarterly_returns,\n",
    "        'Yearly': merged_annual_returns,\n",
    "    }\n",
    "    \n",
    "    return returns_data\n",
    "\n",
    "monthly_returns = {'Portfolio': portfolio_monthly_returns, 'S&P500': sp500_monthly_returns, 'Macro': mom_change_in_macro_data} # compare macro with *cumulative* monthly returns\n",
    "quarterly_returns = {'Portfolio': portfolio_quarterly_returns, 'S&P500': sp500_quarterly_returns, 'Macro': qoq_change_in_macro_data} # compare macro with *cumulative* quarterly returns\n",
    "annual_returns = {'Portfolio': portfolio_annual_returns, 'S&P500': sp500_annual_returns, 'Macro': yoy_change_in_macro_data} # compare macro with *cumulative* annual returns\n",
    "\n",
    "cumulative_monthly_returns = {'Portfolio': portfolio_cumulative_monthly_returns, 'S&P500': sp500_cumulative_monthly_returns, 'Macro': monthly_macro_data} # compare macro with change in monthly returns\n",
    "cumulative_quarterly_returns = {'Portfolio': portfolio_cumulative_quarterly_returns, 'S&P500': sp500_cumulative_quarterly_returns, 'Macro': quarterly_macro_data} # compare macro with change in quarterly returns\n",
    "cumulative_annual_returns = {'Portfolio': portfolio_cumulative_annual_returns, 'S&P500': sp500_cumulative_annual_returns, 'Macro': yoy_change_in_macro_data} # compare macro with change in annual returns\n",
    "\n",
    "plot_portfolio_vs_benchmark_vs_macro(monthly_returns['Portfolio'], monthly_returns['S&P500'], monthly_returns['Macro'], 'Monthly', title_prefix='')\n",
    "plot_portfolio_vs_benchmark_vs_macro(quarterly_returns['Portfolio'], quarterly_returns['S&P500'], quarterly_returns['Macro'], 'Quarterly', title_prefix='')\n",
    "plot_portfolio_vs_benchmark_vs_macro(annual_returns['Portfolio'], annual_returns['S&P500'], annual_returns['Macro'], 'Annual', title_prefix='')\n",
    "\n",
    "plot_portfolio_vs_benchmark_vs_macro(cumulative_monthly_returns['Portfolio'], cumulative_monthly_returns['S&P500'], cumulative_monthly_returns['Macro'], 'Monthly', title_prefix='Cumulative ')\n",
    "plot_portfolio_vs_benchmark_vs_macro(cumulative_quarterly_returns['Portfolio'], cumulative_quarterly_returns['S&P500'], cumulative_quarterly_returns['Macro'], 'Quarterly', title_prefix='Cumulative ')\n",
    "plot_portfolio_vs_benchmark_vs_macro(cumulative_annual_returns['Portfolio'], cumulative_annual_returns['S&P500'], cumulative_annual_returns['Macro'], 'Annual', title_prefix='Cumulative ')\n",
    "\n",
    "# was trying to leverage df's, just became too confusing\n",
    "#combined_returns_data = dict_to_combined_dict_of_df(monthly_returns, quarterly_returns, annual_returns)\n",
    "#combined_cumulative_returns_data = dict_to_combined_dict_of_df(cumulative_monthly_returns, cumulative_quarterly_returns, cumulative_annual_returns)\n",
    "#plot_portfolio_vs_benchmark_vs_macro_altair(combined_returns_data, combined_cumulative_returns_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# was trying to leverage altair to minimize mem impact on the browser, will have to back to this\n",
    "# #plot_portfolio_vs_benchmark_vs_macro_altair(returns_data, cumulative_returns_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import json\n",
    "from pypfopt import expected_returns, EfficientFrontier\n",
    "\n",
    "parent_dir = os.path.abspath('..')\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "    \n",
    "import src.utils as utils\n",
    "import src.macro.calculate as calculate\n",
    "import src.macro.plot as plot\n",
    "\n",
    "def load_latest_tuned_hyperparameters():\n",
    "    # List all files that begin with \"tuned_macro_hyperparameters\"\n",
    "    files = glob.glob('tuned_macro_hyperparameters_*.json')\n",
    "\n",
    "    # If no files found, return None\n",
    "    if not files:\n",
    "        return None\n",
    "\n",
    "    # Sort files by date\n",
    "    files.sort(key=os.path.getmtime, reverse=True)\n",
    "\n",
    "    # Load the most recent file\n",
    "    latest_file = files[0]\n",
    "    with open(latest_file, 'r') as f:\n",
    "        hyper_parameter_dict = json.load(f)\n",
    "\n",
    "    return hyper_parameter_dict\n",
    "\n",
    "date = datetime.now().strftime(\"%Y%m%d\")\n",
    "print(f'date: {date}')\n",
    "\n",
    "cur_tuned_params_dict = load_latest_tuned_hyperparameters()\n",
    "print(f'cur_tuned_params_df:\\n{cur_tuned_params_dict}')\n",
    "\n",
    "def get_combined_returns_data_v0(tickers, start_date, end_date):\n",
    "\n",
    "\n",
    "    # just grabbing the 'Adj Close' column\n",
    "    stock_data = utils.get_stock_data(tickers, start_date, end_date)\n",
    "\n",
    "    sp500_data = stock_data['^GSPC']\n",
    "    stock_data = stock_data.drop(['^GSPC'], axis=1)\n",
    "\n",
    "    stock_data.tail()\n",
    "\n",
    "    \"\"\"similar to portfolio/display.py, set the portfolio weights and calculate the performance\n",
    "    \"\"\"\n",
    "    risk_free_rate = 0.04\n",
    "    mu = expected_returns.mean_historical_return(stock_data)\n",
    "    S = utils.calculate_covariance_matrix(stock_data)\n",
    "\n",
    "    # Calculating the cumulative monthly returns of a portfolio of stocks with given weights:\n",
    "    min_risk, max_risk = utils.calculate_risk_extents(mu, S, risk_free_rate)\n",
    "    risk = (max_risk + min_risk) / 2\n",
    "\n",
    "    ef = EfficientFrontier(mu, S)\n",
    "    ef.efficient_risk(risk)\n",
    "    weights = ef.clean_weights()\n",
    "    weights = pd.Series(weights).reindex(stock_data.columns)\n",
    "    ef_returns, ef_volatility, ef_sharpe = ef.portfolio_performance(risk_free_rate)\n",
    "    print(f'ef weights:\\n{weights}')\n",
    "    print(f'ef performance: {ef_returns, ef_volatility, ef_sharpe}')\n",
    "\n",
    "\n",
    "    daily_returns = stock_data.pct_change()\n",
    "    weighted_daily_returns = daily_returns.mul(weights, axis=1)\n",
    "    portfolio_daily_returns = weighted_daily_returns.sum(axis=1)\n",
    "    portfolio_monthly_returns = portfolio_daily_returns.resample('MS').apply(lambda x: (1 + x).prod() - 1).dropna()\n",
    "    portfolio_quarterly_returns = portfolio_daily_returns.resample('QS').apply(lambda x: (1 + x).prod() - 1).dropna()\n",
    "    portfolio_annual_returns = portfolio_daily_returns.resample('YS').apply(lambda x: (1 + x).prod() - 1).dropna()\n",
    "\n",
    "    portfolio_cumulative_daily_returns = ((1 + portfolio_daily_returns).cumprod() - 1).dropna()\n",
    "    portfolio_cumulative_monthly_returns = ((1 + portfolio_monthly_returns).cumprod() - 1).dropna()\n",
    "    portfolio_cumulative_quarterly_returns = ((1 + portfolio_quarterly_returns).cumprod() - 1).dropna()\n",
    "    portfolio_cumulative_annual_returns = ((1 + portfolio_annual_returns).cumprod() - 1).dropna()\n",
    "\n",
    "    sp500_daily_returns = sp500_data.pct_change()\n",
    "    sp500_monthly_returns = sp500_daily_returns.resample('MS').apply(lambda x: (1 + x).prod() - 1).dropna()\n",
    "    sp500_quarterly_returns = sp500_daily_returns.resample('QS').apply(lambda x: (1 + x).prod() - 1).dropna()\n",
    "    sp500_annual_returns = sp500_daily_returns.resample('YS').apply(lambda x: (1 + x).prod() - 1).dropna()\n",
    "\n",
    "    sp500_cumulative_daily_returns = ((1 + sp500_daily_returns).cumprod() - 1).dropna()\n",
    "    sp500_cumulative_monthly_returns = ((1 + sp500_monthly_returns).cumprod() - 1).dropna()\n",
    "    sp500_cumulative_quarterly_returns = ((1 + sp500_quarterly_returns).cumprod() - 1).dropna()\n",
    "    sp500_cumulative_annual_returns = ((1 + sp500_annual_returns).cumprod() - 1).dropna()    \n",
    "    \n",
    "    macro_data_dict = calculate.get_historical_macro_data(start_date, end_date)\n",
    "\n",
    "    monthly_macro_data = {}\n",
    "    mom_change_in_macro_data = {}\n",
    "\n",
    "    quarterly_macro_data = {}\n",
    "    qoq_change_in_macro_data = {}\n",
    "\n",
    "    yearly_macro_data = {}\n",
    "    yoy_change_in_macro_data = {}\n",
    "\n",
    "    # parse the macro data dictionary into monthly, quarterly, and yearly data for comparison with the portfolio returns\n",
    "    for factor, time_bases in macro_data_dict.items():\n",
    "        for time_basis, time_series in time_bases.items():\n",
    "            if time_basis == 'Monthly':\n",
    "                monthly_macro_data[factor] = time_series.dropna()\n",
    "                \n",
    "            if time_basis == 'Monthly Change': \n",
    "                mom_change_in_macro_data[factor] = time_series.dropna()\n",
    "                \n",
    "            if time_basis == 'Quarterly':\n",
    "                quarterly_macro_data[factor] = time_series.dropna()\n",
    "                \n",
    "            if time_basis == 'Quarterly Change':\n",
    "                qoq_change_in_macro_data[factor] = time_series.dropna()\n",
    "                \n",
    "            if time_basis == 'Yearly':\n",
    "                yearly_macro_data[factor] = time_series.dropna()\n",
    "            \n",
    "            if time_basis == 'Yearly Change':\n",
    "                yoy_change_in_macro_data[factor] = time_series.dropna()\n",
    "                \n",
    "            print(f'{factor} {time_basis}:\\n{time_series.head()}\\n')\n",
    "            \n",
    "    monthly_returns = {'Portfolio': portfolio_monthly_returns, 'S&P500': sp500_monthly_returns, 'Macro': mom_change_in_macro_data} # compare macro with *cumulative* monthly returns\n",
    "    quarterly_returns = {'Portfolio': portfolio_quarterly_returns, 'S&P500': sp500_quarterly_returns, 'Macro': qoq_change_in_macro_data} # compare macro with *cumulative* quarterly returns\n",
    "    annual_returns = {'Portfolio': portfolio_annual_returns, 'S&P500': sp500_annual_returns, 'Macro': yoy_change_in_macro_data} # compare macro with *cumulative* annual returns\n",
    "\n",
    "    cumulative_monthly_returns = {'Portfolio': portfolio_cumulative_monthly_returns, 'S&P500': sp500_cumulative_monthly_returns, 'Macro': monthly_macro_data} # compare macro with change in monthly returns\n",
    "    cumulative_quarterly_returns = {'Portfolio': portfolio_cumulative_quarterly_returns, 'S&P500': sp500_cumulative_quarterly_returns, 'Macro': quarterly_macro_data} # compare macro with change in quarterly returns\n",
    "    cumulative_annual_returns = {'Portfolio': portfolio_cumulative_annual_returns, 'S&P500': sp500_cumulative_annual_returns, 'Macro': yoy_change_in_macro_data} # compare macro with change in annual returns\n",
    "\n",
    "    returns_data = {\n",
    "        'Monthly': monthly_returns,\n",
    "        'Quarterly': quarterly_returns,\n",
    "        'Yearly': annual_returns,\n",
    "    }\n",
    "\n",
    "    cumulative_returns_data = {\n",
    "        'Monthly': cumulative_monthly_returns,\n",
    "        'Quarterly': cumulative_quarterly_returns,\n",
    "        'Yearly': cumulative_annual_returns,\n",
    "    }\n",
    "\n",
    "    return returns_data, cumulative_returns_data\n",
    "\n",
    "def resample_from_daily_stock_returns_series(daily_returns_series):    \n",
    "    portfolio_monthly_returns = portfolio_daily_returns.resample('MS').apply(lambda x: (1 + x).prod() - 1).dropna()\n",
    "    portfolio_quarterly_returns = portfolio_daily_returns.resample('QS').apply(lambda x: (1 + x).prod() - 1).dropna()\n",
    "    portfolio_annual_returns = portfolio_daily_returns.resample('YS').apply(lambda x: (1 + x).prod() - 1).dropna()\n",
    "\n",
    "    portfolio_cumulative_daily_returns = ((1 + portfolio_daily_returns).cumprod() - 1).dropna()\n",
    "    portfolio_cumulative_monthly_returns = ((1 + portfolio_monthly_returns).cumprod() - 1).dropna()\n",
    "    portfolio_cumulative_quarterly_returns = ((1 + portfolio_quarterly_returns).cumprod() - 1).dropna()\n",
    "    portfolio_cumulative_annual_returns = ((1 + portfolio_annual_returns).cumprod() - 1).dropna()\n",
    "    \n",
    "    # establish \"Change\" to imply daily, monthly, etc. returns\n",
    "    # establish w/o \"Change\" to imply cumulative returns\n",
    "    return {\n",
    "        'Daily': portfolio_cumulative_daily_returns, \n",
    "        'Daily Change': portfolio_daily_returns,\n",
    "        'Monthly': portfolio_cumulative_monthly_returns, \n",
    "        'Monthly Change': portfolio_monthly_returns, \n",
    "        'Quarterly': portfolio_cumulative_quarterly_returns, \n",
    "        'Quarterly Change': portfolio_quarterly_returns, \n",
    "        'Yearly': portfolio_cumulative_annual_returns, \n",
    "        'Yearly Change': portfolio_annual_returns\n",
    "    }\n",
    "    \n",
    "def get_historical_portfolio_weighted_returns_data(tickers, start_date, end_date, risk_free_rate=0.04):\n",
    "    # just grabbing the 'Adj Close' column\n",
    "    stock_data = utils.get_stock_data(tickers, start_date, end_date)\n",
    "\n",
    "    \"\"\"similar to portfolio/display.py, set the portfolio weights and calculate the performance\n",
    "    \"\"\"\n",
    "    mu = expected_returns.mean_historical_return(stock_data)\n",
    "    S = utils.calculate_covariance_matrix(stock_data)\n",
    "\n",
    "    # Calculating the cumulative monthly returns of a portfolio of stocks with given weights:\n",
    "    min_risk, max_risk = utils.calculate_risk_extents(mu, S, risk_free_rate)\n",
    "    risk = (max_risk + min_risk) / 2 # set to mid point risk? or max risk?\n",
    "\n",
    "    ef = EfficientFrontier(mu, S)\n",
    "    ef.efficient_risk(risk)\n",
    "    weights = ef.clean_weights()\n",
    "    weights = pd.Series(weights).reindex(stock_data.columns)\n",
    "    ef_returns, ef_volatility, ef_sharpe = ef.portfolio_performance(risk_free_rate)\n",
    "    print(f'ef weights:\\n{weights}')\n",
    "    print(f'ef performance: {ef_returns, ef_volatility, ef_sharpe}')\n",
    "\n",
    "    daily_returns = stock_data.pct_change()\n",
    "    weighted_daily_returns = daily_returns.mul(weights, axis=1)\n",
    "    portfolio_daily_returns = weighted_daily_returns.sum(axis=1)\n",
    "        \n",
    "    # return ticker list with non-zero weights\n",
    "    portfolio_tickers = [ticker for ticker, weight in weights.items() if weight > 0]\n",
    "    \n",
    "    portfolio_returns_dict = resample_from_daily_stock_returns_series(portfolio_daily_returns)\n",
    "        \n",
    "    return portfolio_returns_dict, portfolio_tickers\n",
    "\n",
    "        \n",
    "def get_combined_returns_data(tickers, start_date, end_date):\n",
    "   \n",
    "    sp500_data = utils.get_stock_data(['^GSPC'], start_date, end_date)\n",
    "    sp500_daily_returns = sp500_data.pct_change()\n",
    "    sp500_returns_dict = resample_from_daily_stock_returns_series(sp500_daily_returns)\n",
    "\n",
    "    portfolio_returns_dict, portfolio_tickers = get_historical_portfolio_weighted_returns_data(tickers, start_date, end_date)\n",
    "    macro_data_dict = calculate.get_historical_macro_data(start_date, end_date)\n",
    "\n",
    "    monthly_macro_data = {}\n",
    "    mom_change_in_macro_data = {}\n",
    "\n",
    "    quarterly_macro_data = {}\n",
    "    qoq_change_in_macro_data = {}\n",
    "\n",
    "    yearly_macro_data = {}\n",
    "    yoy_change_in_macro_data = {}\n",
    "       \n",
    "    for factor, time_bases in macro_data_dict.items():\n",
    "        for time_basis, time_series in time_bases.items():\n",
    "            if time_basis == 'Monthly':\n",
    "                monthly_macro_data[factor] = time_series.dropna()\n",
    "                \n",
    "            if time_basis == 'Monthly Change': \n",
    "                mom_change_in_macro_data[factor] = time_series.dropna()\n",
    "                \n",
    "            if time_basis == 'Quarterly':\n",
    "                quarterly_macro_data[factor] = time_series.dropna()\n",
    "                \n",
    "            if time_basis == 'Quarterly Change':\n",
    "                qoq_change_in_macro_data[factor] = time_series.dropna()\n",
    "                \n",
    "            if time_basis == 'Yearly':\n",
    "                yearly_macro_data[factor] = time_series.dropna()\n",
    "            \n",
    "            if time_basis == 'Yearly Change':\n",
    "                yoy_change_in_macro_data[factor] = time_series.dropna()\n",
    "                \n",
    "            print(f'{factor} {time_basis}:\\n{time_series.head()}\\n')\n",
    "            \n",
    "    # what to do with the daily returns? maybe return the portfolio and benchmark daily returns separately?\n",
    "    monthly_returns = {'Portfolio': portfolio_returns_dict['Monthly Change'], 'S&P500': sp500_returns_dict['Monthly Change'], 'Macro': mom_change_in_macro_data} # compare macro with monthly returns\n",
    "    quarterly_returns = {'Portfolio': portfolio_returns_dict['Quarterly Change'], 'S&P500': sp500_returns_dict['Quarterly Change'], 'Macro': qoq_change_in_macro_data} # compare macro with quarterly returns\n",
    "    annual_returns = {'Portfolio': portfolio_returns_dict['Yearly Change'], 'S&P500': sp500_returns_dict['Yearly Change'], 'Macro': yoy_change_in_macro_data} # compare macro with annual returns\n",
    "\n",
    "    cumulative_monthly_returns = {'Portfolio': portfolio_returns_dict['Monthly'], 'S&P500': sp500_returns_dict['Monthly'], 'Macro': monthly_macro_data} # compare macro with cumulative monthly returns\n",
    "    cumulative_quarterly_returns = {'Portfolio': portfolio_returns_dict['Quarterly'], 'S&P500': sp500_returns_dict['Quarterly'], 'Macro': quarterly_macro_data} # compare macro with cumulative quarterly returns\n",
    "    cumulative_annual_returns = {'Portfolio': portfolio_returns_dict['Yearly'], 'S&P500': sp500_returns_dict['Yearly'], 'Macro': yoy_change_in_macro_data} # compare macro with cumulative annual returns\n",
    "\n",
    "    combined_returns_data = {\n",
    "        'Monthly': monthly_returns,\n",
    "        'Quarterly': quarterly_returns,\n",
    "        'Yearly': annual_returns,\n",
    "    }\n",
    "\n",
    "    combined_cumulative_returns_data = {\n",
    "        'Monthly': cumulative_monthly_returns,\n",
    "        'Quarterly': cumulative_quarterly_returns,\n",
    "        'Yearly': cumulative_annual_returns,\n",
    "    }\n",
    "\n",
    "    return combined_returns_data, combined_cumulative_returns_data, portfolio_returns_dict, sp500_returns_dict, macro_data_dict, portfolio_tickers\n",
    "\n",
    "tickers = ['AAPL','AMZN','NVDA','MMC','GOOG','MSFT','BTC-USD','ETH-USD','XOM','BAC','V','GOLD','^GSPC']\n",
    "start_date = '2010-01-01'\n",
    "end_date = datetime.now() - timedelta(1)\n",
    "    \n",
    "returns_data, cumulative_returns_data, portfolio_returns_dict, sp500_returns_dict, macro_data_dict, portfolio_tickers = get_combined_returns_data(tickers, start_date, end_date)\n",
    "\n",
    "for time_basis, returns in returns_data.items():\n",
    "    print(f'Portfolio {time_basis} returns index:\\n{type(returns[\"Portfolio\"].index)}\\n')\n",
    "    for factor, series in returns['Macro'].items():\n",
    "        print(f'Macro {factor} {time_basis} returns index:\\n{type(series.index)}\\n')\n",
    "    \n",
    "for time_basis, returns in cumulative_returns_data.items():\n",
    "    print(f'Portfolio {time_basis} cumulative returns index:\\n{type(returns[\"Portfolio\"].index)}\\n')\n",
    "    for factor, series in returns['Macro'].items():\n",
    "        print(f'Macro {factor} {time_basis} cumulative returns index:\\n{type(series.index)}\\n')\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VAR processing: Prepare the data: You would first make sure that your macroeconomic data and returns data are of the same frequency (monthly in this case) and have the same time period. It's also important to ensure that there are no missing values.\n",
    "\n",
    "Stationarity check: The VAR model requires the data to be stationary. Therefore, you would need to check if the data is stationary or not. If not, differences of the series might need to be taken.\n",
    "\n",
    "Choose the order of the VAR model: You would need to select the lag order for the VAR model. This could be done using various statistical criteria like the Akaike Information Criterion (AIC) or the Bayesian Information Criterion (BIC).\n",
    "\n",
    "Fit the VAR model: Once the data is ready and the order is selected, you can fit the VAR model to your data. This would give you the parameters of the model.\n",
    "\n",
    "Check for serial correlation of residuals: After fitting the VAR model, you would want to check if there's any autocorrelation in the residuals because the residuals of a well-specified VAR are supposed to be white noise. If there's autocorrelation, the model might be mis-specified.\n",
    "\n",
    "Forecasting: Once the VAR model is ready and validated, you can use it to make forecasts about your portfolio returns and macroeconomic factors for the next period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from statsmodels.api import OLS\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.stattools import ccf\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.subplots as sp\n",
    "import colorsys\n",
    "\n",
    "# Aligning the dataframes\n",
    "def align_dataframes(dfs):\n",
    "    # Get the common datetime index\n",
    "    common_index = dfs[0].index\n",
    "    for df in dfs[1:]:\n",
    "        common_index = common_index.intersection(df.index)\n",
    "    \n",
    "    # Align all dataframes to the common index\n",
    "    aligned_dfs = [df.loc[common_index] for df in dfs]\n",
    "    return aligned_dfs\n",
    "\n",
    "def prepare_data(returns_data):\n",
    "    portfolio_returns = returns_data['Monthly']['Portfolio'].to_frame(name='Portfolio')\n",
    "    sp500_returns = returns_data['Monthly']['S&P500'].to_frame(name='S&P500')\n",
    "\n",
    "    # concat sp500 with portfolio returns\n",
    "    portfolio_returns = pd.concat([portfolio_returns, sp500_returns], axis=1)\n",
    "\n",
    "    # Loop through all macro factors and add to DataFrame\n",
    "    for factor_name, factor_df in returns_data['Monthly']['Macro'].items():\n",
    "        factor_df = factor_df.rename(factor_name)  # Rename the series\n",
    "        portfolio_returns = pd.concat([portfolio_returns, factor_df], axis=1)\n",
    "\n",
    "    # Use align_dataframes to ensure the data is properly aligned\n",
    "    aligned_data = align_dataframes([portfolio_returns])\n",
    "\n",
    "    aligned_data[0].index = pd.to_datetime(aligned_data[0].index)\n",
    "    aligned_data[0] = aligned_data[0].dropna()\n",
    "    \n",
    "    return aligned_data[0]  # align_dataframes returns a list, so we take the first element\n",
    "\n",
    "\"\"\"\n",
    "The check_multicollinearity() function calculates the Variance Inflation Factor (VIF) for each macro factor. \n",
    "VIF measures the correlation between each factor and all other factors. If a factor's VIF exceeds a certain \n",
    "threshold (in this case, 5), it indicates high multicollinearity.\n",
    "\"\"\"\n",
    "def check_multicollinearity(df, vif_threshold=5):\n",
    "    df = df.copy()\n",
    "    df.drop('Portfolio',axis=1,inplace=True)\n",
    "    \n",
    "    variables = df.columns\n",
    "    vif_df = pd.DataFrame()\n",
    "    vif_df[\"VIF\"] = [variance_inflation_factor(df[variables].values, df.columns.get_loc(var)) for var in df.columns]\n",
    "    vif_df[\"Features\"] = variables\n",
    "\n",
    "    columns_to_drop = []\n",
    "    while vif_df['VIF'].max() > vif_threshold:\n",
    "        remove = vif_df.sort_values('VIF',ascending=False)['Features'][:1]\n",
    "        columns_to_drop.append(remove.values[0])\n",
    "        df.drop(remove,axis=1,inplace=True)\n",
    "        variables = df.columns\n",
    "        vif_df = pd.DataFrame()\n",
    "        vif_df[\"VIF\"] = [variance_inflation_factor(df[variables].values, df.columns.get_loc(var)) for var in df.columns]\n",
    "        vif_df[\"Features\"] = variables\n",
    "    return columns_to_drop\n",
    "\n",
    "def get_factor_list(df):\n",
    "    factor_list = list(df.columns)\n",
    "    factor_list.remove('Portfolio')\n",
    "    factor_list.remove('S&P500')\n",
    "    return factor_list\n",
    "\n",
    "def calculate_linear_regression_model_for_factor(input_df, factor):\n",
    "    df = input_df.copy()\n",
    "    df = df.dropna(how='any').reset_index(drop=True)\n",
    "    X = df[[factor]]\n",
    "    y = df['Portfolio']\n",
    "    X2 = add_constant(X)\n",
    "    model = OLS(y, X2).fit()\n",
    "    coefficient = model.params[factor]\n",
    "    p_value = model.pvalues[factor]\n",
    "    return model, coefficient, p_value\n",
    "\n",
    "def calculate_multivariate_analysis(input_df):\n",
    "    df = input_df.copy()\n",
    "    df = df.dropna(how='any').reset_index(drop=True)\n",
    "    X = df[get_factor_list(df)]  \n",
    "    y = df['Portfolio']\n",
    "    \n",
    "    model = OLS(y, add_constant(X)).fit()\n",
    "    \n",
    "    # Extract the significant features based on p-values\n",
    "    significant_features = model.pvalues[model.pvalues < 0.05].index.tolist()\n",
    "    \n",
    "    if 'const' in significant_features:\n",
    "        significant_features.remove('const')\n",
    "        \n",
    "    return model, significant_features\n",
    "\n",
    "def plot_multivariate_results(input_df, multivariate_model, significant_features):\n",
    "    fig = go.Figure(data=[go.Bar(name='Coefficient', x=multivariate_model.params.index, y=multivariate_model.params.values), \n",
    "                          go.Bar(name='p-value', x=multivariate_model.pvalues.index, y=multivariate_model.pvalues.values)])\n",
    "    fig.update_layout(barmode='group', title_text='Multivariate Regression Results')\n",
    "    fig.show()\n",
    "\n",
    "    # Scatter plots for each significant feature\n",
    "    for feature in significant_features:\n",
    "        # Calculate the OLS trendline\n",
    "        m, b = np.polyfit(input_df[feature], input_df['Portfolio'], 1)\n",
    "\n",
    "        fig2 = go.Figure()\n",
    "        fig2.add_trace(go.Scatter(x=input_df[feature], y=input_df['Portfolio'], mode='markers', name='observations'))\n",
    "        fig2.add_trace(go.Scatter(x=input_df[feature], y=m*input_df[feature] + b, mode='lines', name='OLS trendline'))\n",
    "        fig2.update_layout(title=f'Portfolio Returns vs {feature}', xaxis_title=feature, yaxis_title='Portfolio Returns')\n",
    "        fig2.show()\n",
    "\n",
    "def plot_linear_regression_results_v0(regression_model_dict):\n",
    "    factors = list(regression_model_dict.keys())\n",
    "    coefficients = [regression_model_dict[factor]['linear']['coefficient'] for factor in factors]\n",
    "    p_values = [regression_model_dict[factor]['linear']['p_value'] for factor in factors]\n",
    "\n",
    "    # Order by p-values\n",
    "    ordered_indices = np.argsort(p_values)\n",
    "    factors_ordered = np.array(factors)[ordered_indices]\n",
    "    coefficients_ordered = np.array(coefficients)[ordered_indices]\n",
    "    p_values_ordered = np.array(p_values)[ordered_indices]\n",
    "\n",
    "    fig = sp.make_subplots(rows=2, cols=1, subplot_titles=(\"Coefficients\", \"p-values\"), vertical_spacing=0.1)\n",
    "\n",
    "    # Coefficients\n",
    "    fig.add_trace(\n",
    "        go.Bar(name='Coefficient', x=factors_ordered, y=coefficients_ordered, marker=dict(color=coefficients_ordered, colorscale='balance', showscale=True)), \n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # P-values\n",
    "    fig.add_trace(\n",
    "        go.Bar(name='p-value', x=factors_ordered, y=p_values_ordered), \n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "    # add line at p=0.05\n",
    "    fig.add_shape(type=\"line\", x0=-0.5, y0=0.05, x1=len(factors)-0.5, y1=0.05, yref=\"y2\", line=dict(color=\"red\", dash=\"dash\"))\n",
    "\n",
    "    fig.update_layout(title_text='Linear Regression Results', showlegend=False)\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "def plot_linear_regression_results(regression_models_df):\n",
    "    factors = regression_models_df['Factor'].tolist()\n",
    "    coefficients = regression_models_df['Coefficient'].tolist()\n",
    "    p_values = regression_models_df['p-value'].tolist()\n",
    "\n",
    "    # Order by p-values\n",
    "    ordered_indices = np.argsort(p_values)\n",
    "    factors_ordered = np.array(factors)[ordered_indices]\n",
    "    coefficients_ordered = np.array(coefficients)[ordered_indices]\n",
    "    p_values_ordered = np.array(p_values)[ordered_indices]\n",
    "\n",
    "    fig = sp.make_subplots(rows=2, cols=1, subplot_titles=(\"Coefficients\", \"p-values\"), vertical_spacing=0.1)\n",
    "\n",
    "    # Coefficients\n",
    "    fig.add_trace(\n",
    "        go.Bar(name='Coefficient', x=factors_ordered, y=coefficients_ordered, marker=dict(color=coefficients_ordered, colorscale='balance', showscale=True)), \n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # P-values\n",
    "    fig.add_trace(\n",
    "        go.Bar(name='p-value', x=factors_ordered, y=p_values_ordered), \n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "    # add line at p=0.05\n",
    "    fig.add_shape(type=\"line\", x0=-0.5, y0=0.05, x1=len(factors)-0.5, y1=0.05, yref=\"y2\", line=dict(color=\"red\", dash=\"dash\"))\n",
    "\n",
    "    fig.update_layout(title_text='Linear Regression Results', showlegend=False)\n",
    "\n",
    "    fig.show()\n",
    "    \n",
    "\"\"\"\n",
    "1. Portfolio Performance vs Factor over Time: This plot shows the portfolio returns and the given factor (e.g., S&P 500, unemployment rate, GDP growth, etc.) over time. \n",
    "You want to see if there are any visible patterns or correlations. Do they seem to move together (i.e., both go up or down at the same time)? Do they move in opposite \n",
    "directions? If there's a visible relationship, that's a good sign that your factor may be a useful predictor. Of course, you'd have to validate this with more rigorous \n",
    "statistical tests.\n",
    "\n",
    "2. Scatter of Portfolio Returns vs Factor: This plot shows each observation of your portfolio returns against the factor. You're looking for any kind of relationship - \n",
    "linear, non-linear, or no relationship at all. A linear relationship where the points cluster around a straight line (either increasing or decreasing) is a good sign \n",
    "that linear regression may be a good model. If you see a different pattern, like a curve or clusters, a different model might be more appropriate.\n",
    "\n",
    "3. Linear Regression Model Performance Prediction vs Actual Values: In this plot, you want the predicted values to be as close to the actual values as possible. In other \n",
    "words, the dots should be close to the fitted line. If the points scatter widely around the line, your model might not be a great fit.\n",
    "\n",
    "4. Regression Model Residuals (error) vs Predicted Values: This plot shows the residuals (errors) of your model against the predicted values. In a well-performing model, \n",
    "you'd expect to see the residuals scattered randomly around the zero line. If you see patterns in the residuals, like a curve or a funnel shape, it's a sign that your \n",
    "model isn't capturing some aspect of the data.\n",
    "\n",
    "In terms of mathematical measures:\n",
    "\n",
    "R-squared: This is a measure of how well your model fits the data. It's a number between 0 and 1, where 1 means a perfect fit and 0 means no fit at all. Generally, a \n",
    "higher R-squared indicates a better fit, but beware of overfitting if your R-squared is very close to 1.\n",
    "\n",
    "Correlation: This is a measure of the linear relationship between two variables. It ranges from -1 to 1. A positive correlation means that when one variable increases, \n",
    "the other tends to increase, too. A negative correlation means that when one variable increases, the other tends to decrease. A correlation close to 0 means there's no \n",
    "linear relationship.\n",
    "\n",
    "Remember that correlation does not imply causation - just because two variables move together doesn't mean one is causing the other to move. It could be a coincidence, \n",
    "or there could be a third factor causing both to move.\n",
    "\n",
    "Regression coefficients (slope and intercept): These numbers tell you the exact mathematical relationship between your predictor and the response. The slope tells you \n",
    "how much the response is expected to change when the predictor increases by one unit. The intercept tells you the expected response when the predictor is zero.\n",
    "These are some of the key things to look for when performing linear regression analysis. Each situation is unique, and you may need to use other techniques and consider \n",
    "other factors depending on your specific dataset and research question.\n",
    "\n",
    "\"\"\"\n",
    "def create_linear_regression_plots_v0(df, factor, regression_models_dict, time_basis, cumulative_performance):\n",
    "    linear_regression_model = regression_models_dict[factor]['linear']['model']\n",
    "    \n",
    "    X = df[[factor]]\n",
    "    y = df['Portfolio']\n",
    "    X2 = add_constant(X)\n",
    "    predictions = linear_regression_model.predict(X2)\n",
    "    residuals = y - predictions\n",
    "\n",
    "    # Intercept and slope for the annotation\n",
    "    intercept = linear_regression_model.params['const']\n",
    "    slope = linear_regression_model.params[factor]\n",
    "\n",
    "    # Correlation between the factor and the portfolio returns\n",
    "    correlation = df[\"Portfolio\"].corr(df[factor])\n",
    "\n",
    "    if cumulative_performance:\n",
    "        # Initialize subplots\n",
    "        fig = sp.make_subplots(rows=1, cols=4, subplot_titles=(f\"Portfolio Returns vs<br>{factor} over Time\", f\"Scatter of Portfolio Returns vs<br>{factor}\", f\"Model Prediction of Returns vs<br>{factor}\", f\"Regression Model Residuals (error) vs<br>{factor}\"),  specs=[[{'secondary_y': True}, {'secondary_y': True}, {'secondary_y': True}, {}]])\n",
    "    else:\n",
    "        fig = sp.make_subplots(rows=1, cols=4, subplot_titles=(f\"Portfolio Returns vs<br>{time_basis} Change of {factor}\", f\"Scatter of Portfolio Returns vs<br>{time_basis} Change of {factor}\", f\"Model Prediction of Returns vs<br>{time_basis} Change of {factor}\", f\"Regression Model Residuals (error) vs<br>{time_basis} Change of {factor}\"),  specs=[[{'secondary_y': True}, {'secondary_y': True}, {'secondary_y': True}, {}]])\n",
    "\n",
    "    # Subplot 1: Portfolio vs Factor over time\n",
    "    fig.add_trace(go.Scatter(x=df.index, y=df[\"Portfolio\"], mode='lines', name='Portfolio', line=dict(color='royalblue')), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=df.index, y=df[factor], mode='lines', name=factor, line=dict(dash='dot')), secondary_y=True, row=1, col=1)\n",
    "   \n",
    "    # Set range based on respective variable - if not cumulative performance we're comparing month to month percetange change, center the y-axis at 0\n",
    "    if cumulative_performance:\n",
    "        # we're comparing cumulative returns which cannot be negative, so let the range be what it is\n",
    "        fig.update_yaxes(title_text=\"Actual Returns\", tickformat=\".1%\", row=1, col=1)\n",
    "        if 'Rate' in factor:\n",
    "            fig.update_yaxes(title_text=factor, tickformat=\".1%\", secondary_y=True, row=1, col=1)\n",
    "        else:\n",
    "            fig.update_yaxes(title_text=factor, tickformat=\"\", secondary_y=True, row=1, col=1)        \n",
    "    else:\n",
    "        # we're comparing month to month percetange change, center the y-axis at 0\n",
    "        y_range = max(abs(df[\"Portfolio\"])) + 0.1*max(abs(df[\"Portfolio\"])) # max absolute value of portfolio returns + 5% buffer for visuals\n",
    "        secondary_y_range = max(abs(df[factor])) + 0.1*max(abs(df[factor]))\n",
    "        \n",
    "        fig.update_yaxes(title_text=\"Actual Returns\", range=[-y_range, y_range], tickformat=\".1%\", row=1, col=1)        \n",
    "        fig.update_yaxes(title_text=f'{time_basis} Change of<br>{factor}', range=[-secondary_y_range, secondary_y_range], tickformat=\".1%\", secondary_y=True, row=1, col=1)\n",
    "\n",
    "\n",
    "    # Subplot 2: Scatter of Portfolio Returns vs Factor\n",
    "    fig.add_trace(go.Scatter(x=df[factor], y=df[\"Portfolio\"], mode='markers', name='Scatter of Factor vs Portfolio', marker=dict(size=10, color='rgba(0, 0, 152, .8)')), row=1, col=2)\n",
    "    fig.add_trace(go.Scatter(x=df[factor], y=intercept + slope * df[factor], mode='lines', name='Model Fitted line', line=dict(color='red', width=2)), row=1, col=2)\n",
    "    \n",
    "    # Set range based on respective variable\n",
    "    if cumulative_performance:\n",
    "        # cumulative returns cannot be negative, so let the range be what it is\n",
    "        fig.update_yaxes(title_text=\"Actual Returns\", tickformat=\".1%\", row=1, col=2)   \n",
    "        if 'Rate' in factor: # add % sign to tick labels if the factor is a rate, eg, unemployment rate\n",
    "            fig.update_xaxes(title_text=factor, tickformat=\".1%\", row=1, col=2)    \n",
    "        else:\n",
    "            fig.update_xaxes(title_text=factor, row=1, col=2)\n",
    "    else:\n",
    "        # we're comparing month to month percetange change, center the y-axis at 0\n",
    "        x_range = max(abs(df[factor])) + 0.1*max(abs(df[factor])) # max absolute value of factor + 5% buffer for visuals\n",
    "        y_range = max(abs(df[\"Portfolio\"])) + 0.1*max(abs(df[\"Portfolio\"])) # max absolute value of portfolio returns + 5% buffer for visuals\n",
    "        \n",
    "        fig.update_xaxes(title_text=f'{time_basis} Change of<br>{factor}', range=[-x_range, x_range], tickformat=\".1%\", row=1, col=2)\n",
    "        fig.update_yaxes(title_text=f\"Actual {time_basis} Returns\", range=[-y_range, y_range], tickformat=\".1%\", row=1, col=2)\n",
    "\n",
    "\n",
    "    # Subplot 3: Predicted Return vs Actual Factor Values \n",
    "    fig.add_trace(go.Scatter(x=df[factor], y=predictions, mode='markers', name='Model Predicted vs Actual Factor', marker=dict(size=10, color='rgba(0, 152, 0, .8)')), row=1, col=3)\n",
    "    if cumulative_performance:\n",
    "        # cumulative returns cannot be negative, so let the range be what it is\n",
    "        fig.update_yaxes(title_text=f\"Predicted Cumulative {time_basis} Returns\", tickformat=\".1%\", row=1, col=3)\n",
    "        if 'Rate' in factor:\n",
    "            fig.update_xaxes(title_text=f\"{factor}\", tickformat=\".1%\", row=1, col=3)\n",
    "        else:\n",
    "            fig.update_xaxes(title_text=f\"{factor}\", row=1, col=3)\n",
    "    else:\n",
    "        fig.update_xaxes(title_text=f\"{time_basis} Change of<br>{factor}\", tickformat=\".1%\", row=1, col=3)\n",
    "        fig.update_yaxes(title_text=f\"Predicted {time_basis} Returns\", tickformat=\".1%\", row=1, col=3)\n",
    "\n",
    "    # Subplot 4: Residuals vs Factor Values\n",
    "    fig.add_trace(go.Scatter(x=df[factor], y=residuals, mode='markers', name='Residuals vs Factor', marker=dict(size=10, color='rgba(152, 0, 0, .8)')), row=1, col=4)\n",
    "    fig.update_yaxes(title_text=\"Residuals\", tickformat=\".1%\", row=1, col=4)\n",
    "    if cumulative_performance:\n",
    "        if 'Rate' in factor:\n",
    "            fig.update_xaxes(title_text=f\"{factor}\", tickformat=\".1%\", row=1, col=4)\n",
    "        else:\n",
    "            fig.update_xaxes(title_text=f\"{factor}\", row=1, col=4)\n",
    "    else:\n",
    "        fig.update_xaxes(title_text=f\"{time_basis} Change of<br>{factor}\", tickformat=\".1%\", row=1, col=4)\n",
    "\n",
    "    # Update subplot titles and axis labels to be a little smaller\n",
    "    for annotation in fig['layout']['annotations']: \n",
    "        annotation['font']['size']=12\n",
    "    fig.update_xaxes(tickfont=dict(size=12), title_font=dict(size=12))\n",
    "    fig.for_each_yaxis(lambda axis: axis.update(tickfont=dict(size=12), title_font=dict(size=12)))\n",
    "    fig.add_annotation(x=0.65, y=0.95, xref=\"paper\", yref=\"paper\", text=f\"R-squared = {linear_regression_model.rsquared:.3f}\", showarrow=False, font=dict(size=8))\n",
    "    fig.add_annotation(x=0.65, y=0.90, xref=\"paper\", yref=\"paper\", text=f\"f(x) = {slope:.3f} * x + {intercept:.3f}\", showarrow=False, font=dict(size=8))\n",
    "    fig.add_annotation(x=0.65, y=0.85, xref=\"paper\", yref=\"paper\", text=f\"Correlation = {correlation:.3f}\", showarrow=False, font=dict(size=8))\n",
    "        \n",
    "    lag = regression_models_dict[factor]['linear']['optimal_lag']\n",
    "    if cumulative_performance:\n",
    "        fig.update_layout(title_text=f\"Linear Regression Analysis and Model of {time_basis} Returns vs. {factor} (lag={lag}))\")\n",
    "    else:\n",
    "        \n",
    "        fig.update_layout(title_text=f\"Linear Regression Analysis and Model of {time_basis} Returns vs. {factor} {time_basis} Change (%) (lag={lag}))\")\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_linear_regression_plots(input_df, factor, regression_models_df, time_basis, cumulative_performance):\n",
    "    linear_regression_model = regression_models_df.loc[regression_models_df['Factor'] == factor, 'Model'].values[0]\n",
    "    df = input_df.copy()\n",
    "    df = df.dropna(how='any').reset_index(drop=True)\n",
    "    \n",
    "    X = df[[factor]]\n",
    "    y = df['Portfolio']\n",
    "    X2 = add_constant(X)\n",
    "    predictions = linear_regression_model.predict(X2)\n",
    "    residuals = y - predictions\n",
    "\n",
    "    # Intercept and slope for the annotation\n",
    "    intercept = linear_regression_model.params['const']\n",
    "    slope = linear_regression_model.params[factor]\n",
    "\n",
    "    # Correlation between the factor and the portfolio returns\n",
    "    correlation = df[\"Portfolio\"].corr(df[factor])\n",
    "\n",
    "    if cumulative_performance:\n",
    "        # Initialize subplots\n",
    "        fig = sp.make_subplots(rows=1, cols=4, subplot_titles=(f\"Portfolio Returns vs<br>{factor} over Time\", f\"Scatter of Portfolio Returns vs<br>{factor}\", f\"Model Prediction of Returns vs<br>{factor}\", f\"Regression Model Residuals (error) vs<br>{factor}\"),  specs=[[{'secondary_y': True}, {'secondary_y': True}, {'secondary_y': True}, {}]])\n",
    "    else:\n",
    "        fig = sp.make_subplots(rows=1, cols=4, subplot_titles=(f\"Portfolio Returns vs<br>{time_basis} Change of {factor}\", f\"Scatter of Portfolio Returns vs<br>{time_basis} Change of {factor}\", f\"Model Prediction of Returns vs<br>{time_basis} Change of {factor}\", f\"Regression Model Residuals (error) vs<br>{time_basis} Change of {factor}\"),  specs=[[{'secondary_y': True}, {'secondary_y': True}, {'secondary_y': True}, {}]])\n",
    "\n",
    "    # Subplot 1: Portfolio vs Factor over time\n",
    "    fig.add_trace(go.Scatter(x=df.index, y=df[\"Portfolio\"], mode='lines', name='Portfolio', line=dict(color='royalblue')), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=df.index, y=df[factor], mode='lines', name=factor, line=dict(dash='dot')), secondary_y=True, row=1, col=1)\n",
    "   \n",
    "    # Set range based on respective variable - if not cumulative performance we're comparing month to month percetange change, center the y-axis at 0\n",
    "    if cumulative_performance:\n",
    "        # we're comparing cumulative returns which cannot be negative, so let the range be what it is\n",
    "        fig.update_yaxes(title_text=\"Actual Returns\", tickformat=\".1%\", row=1, col=1)\n",
    "        if 'Rate' in factor:\n",
    "            fig.update_yaxes(title_text=factor, tickformat=\".1%\", secondary_y=True, row=1, col=1)\n",
    "        else:\n",
    "            fig.update_yaxes(title_text=factor, tickformat=\"\", secondary_y=True, row=1, col=1)        \n",
    "    else:\n",
    "        # we're comparing month to month percetange change, center the y-axis at 0\n",
    "        y_range = max(abs(df[\"Portfolio\"])) + 0.1*max(abs(df[\"Portfolio\"])) # max absolute value of portfolio returns + 5% buffer for visuals\n",
    "        secondary_y_range = max(abs(df[factor])) + 0.1*max(abs(df[factor]))\n",
    "        \n",
    "        fig.update_yaxes(title_text=\"Actual Returns\", range=[-y_range, y_range], tickformat=\".1%\", row=1, col=1)        \n",
    "        fig.update_yaxes(title_text=f'{time_basis} Change of<br>{factor}', range=[-secondary_y_range, secondary_y_range], tickformat=\".1%\", secondary_y=True, row=1, col=1)\n",
    "\n",
    "\n",
    "    # Subplot 2: Scatter of Portfolio Returns vs Factor\n",
    "    fig.add_trace(go.Scatter(x=df[factor], y=df[\"Portfolio\"], mode='markers', name='Scatter of Factor vs Portfolio', marker=dict(size=10, color='rgba(0, 0, 152, .8)')), row=1, col=2)\n",
    "    fig.add_trace(go.Scatter(x=df[factor], y=intercept + slope * df[factor], mode='lines', name='Model Fitted line', line=dict(color='red', width=2)), row=1, col=2)\n",
    "    \n",
    "    # Set range based on respective variable\n",
    "    if cumulative_performance:\n",
    "        # cumulative returns cannot be negative, so let the range be what it is\n",
    "        fig.update_yaxes(title_text=\"Actual Returns\", tickformat=\".1%\", row=1, col=2)   \n",
    "        if 'Rate' in factor: # add % sign to tick labels if the factor is a rate, eg, unemployment rate\n",
    "            fig.update_xaxes(title_text=factor, tickformat=\".1%\", row=1, col=2)    \n",
    "        else:\n",
    "            fig.update_xaxes(title_text=factor, row=1, col=2)\n",
    "    else:\n",
    "        # we're comparing month to month percetange change, center the y-axis at 0\n",
    "        x_range = max(abs(df[factor])) + 0.1*max(abs(df[factor])) # max absolute value of factor + 5% buffer for visuals\n",
    "        y_range = max(abs(df[\"Portfolio\"])) + 0.1*max(abs(df[\"Portfolio\"])) # max absolute value of portfolio returns + 5% buffer for visuals\n",
    "        \n",
    "        fig.update_xaxes(title_text=f'{time_basis} Change of<br>{factor}', range=[-x_range, x_range], tickformat=\".1%\", row=1, col=2)\n",
    "        fig.update_yaxes(title_text=f\"Actual {time_basis} Returns\", range=[-y_range, y_range], tickformat=\".1%\", row=1, col=2)\n",
    "\n",
    "\n",
    "    # Subplot 3: Predicted Return vs Actual Factor Values \n",
    "    fig.add_trace(go.Scatter(x=df[factor], y=predictions, mode='markers', name='Model Predicted vs Actual Factor', marker=dict(size=10, color='rgba(0, 152, 0, .8)')), row=1, col=3)\n",
    "    if cumulative_performance:\n",
    "        # cumulative returns cannot be negative, so let the range be what it is\n",
    "        fig.update_yaxes(title_text=f\"Predicted Cumulative {time_basis} Returns\", tickformat=\".1%\", row=1, col=3)\n",
    "        if 'Rate' in factor:\n",
    "            fig.update_xaxes(title_text=f\"{factor}\", tickformat=\".1%\", row=1, col=3)\n",
    "        else:\n",
    "            fig.update_xaxes(title_text=f\"{factor}\", row=1, col=3)\n",
    "    else:\n",
    "        fig.update_xaxes(title_text=f\"{time_basis} Change of<br>{factor}\", tickformat=\".1%\", row=1, col=3)\n",
    "        fig.update_yaxes(title_text=f\"Predicted {time_basis} Returns\", tickformat=\".1%\", row=1, col=3)\n",
    "\n",
    "    # Subplot 4: Residuals vs Factor Values\n",
    "    fig.add_trace(go.Scatter(x=df[factor], y=residuals, mode='markers', name='Residuals vs Factor', marker=dict(size=10, color='rgba(152, 0, 0, .8)')), row=1, col=4)\n",
    "    fig.update_yaxes(title_text=\"Residuals\", tickformat=\".1%\", row=1, col=4)\n",
    "    if cumulative_performance:\n",
    "        if 'Rate' in factor:\n",
    "            fig.update_xaxes(title_text=f\"{factor}\", tickformat=\".1%\", row=1, col=4)\n",
    "        else:\n",
    "            fig.update_xaxes(title_text=f\"{factor}\", row=1, col=4)\n",
    "    else:\n",
    "        fig.update_xaxes(title_text=f\"{time_basis} Change of<br>{factor}\", tickformat=\".1%\", row=1, col=4)\n",
    "\n",
    "    # Update subplot titles and axis labels to be a little smaller\n",
    "    for annotation in fig['layout']['annotations']: \n",
    "        annotation['font']['size']=12\n",
    "    fig.update_xaxes(tickfont=dict(size=12), title_font=dict(size=12))\n",
    "    fig.for_each_yaxis(lambda axis: axis.update(tickfont=dict(size=12), title_font=dict(size=12)))\n",
    "    fig.add_annotation(x=0.65, y=0.95, xref=\"paper\", yref=\"paper\", text=f\"R-squared = {linear_regression_model.rsquared:.3f}\", showarrow=False, font=dict(size=8))\n",
    "    fig.add_annotation(x=0.65, y=0.90, xref=\"paper\", yref=\"paper\", text=f\"f(x) = {slope:.3f} * x + {intercept:.3f}\", showarrow=False, font=dict(size=8))\n",
    "    fig.add_annotation(x=0.65, y=0.85, xref=\"paper\", yref=\"paper\", text=f\"Correlation = {correlation:.3f}\", showarrow=False, font=dict(size=8))\n",
    "        \n",
    "    lag = regression_models_df.loc[regression_models_df['Factor'] == factor, 'Optimal Lag'].values[0]\n",
    "\n",
    "    if cumulative_performance:\n",
    "        fig.update_layout(title_text=f\"Linear Regression Analysis and Model of {time_basis} Returns vs. {factor} (lag={lag}))\")\n",
    "    else:\n",
    "        \n",
    "        fig.update_layout(title_text=f\"Linear Regression Analysis and Model of {time_basis} Returns vs. {factor} {time_basis} Change (%) (lag={lag}))\")\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def check_stationarity(series):\n",
    "    \"\"\"\n",
    "    Perform Dickey-Fuller test and check for stationarity of a given series.\n",
    "    \"\"\"\n",
    "    result = adfuller(series)\n",
    "    return result[1] <= 0.05  # If p-value is less than 0.05, the series is stationary\n",
    "\n",
    "def create_var_model(data, maxlag=6, vif_threshold=5):\n",
    "    # Ensure data is stationary\n",
    "    non_stationary_columns = [column for column in data.columns if not check_stationarity(data[column])]\n",
    "    if non_stationary_columns:\n",
    "        # Difference non-stationary series\n",
    "        data[non_stationary_columns] = data[non_stationary_columns].diff()\n",
    "        # Drop the first row in all series\n",
    "        data = data.dropna()\n",
    "\n",
    "    threshold = 0.001 # if any columns with less than a 0.1% standard deviation, just drop it as more or less constant\n",
    "    near_constant_columns = data.columns[data.std() < threshold]\n",
    "    print('Near constant columns:', near_constant_columns)\n",
    "    data = data.drop(columns=near_constant_columns)\n",
    "\n",
    "    # Get the list of columns to drop based on high correlation to each other\n",
    "    columns_to_drop = check_multicollinearity(data, vif_threshold)\n",
    "    if columns_to_drop is None:\n",
    "        columns_to_drop = []\n",
    "    print(f'After check_multicollinearity(), columns to drop: {columns_to_drop}')\n",
    "\n",
    "    # Add columns with high correlation to the columns to drop list\n",
    "    corr_matrix = data.corr()\n",
    "    for i in range(len(data.columns)):\n",
    "        for j in range(i+1, len(data.columns)):\n",
    "            if abs(corr_matrix.iloc[i,j]) > 0.8:\n",
    "                col_i = data.columns[i]\n",
    "                col_j = data.columns[j]\n",
    "                if col_i not in columns_to_drop and col_j not in columns_to_drop:\n",
    "                    print(f'Adding columns {col_i} and {col_j} to columns_to_drop')\n",
    "                    columns_to_drop.append(col_i)\n",
    "                    columns_to_drop.append(col_j)\n",
    "\n",
    "    # Create the VAR model with all columns\n",
    "    best_model = None\n",
    "    best_aic = np.inf\n",
    "    try:\n",
    "        # Create the VAR model\n",
    "        model = VAR(data)\n",
    "\n",
    "        # Fit the model with the optimal lag order\n",
    "        results = model.fit(ic='aic')\n",
    "        print(f'VAR model results:\\n{results.summary()}')\n",
    "\n",
    "        # Update the best model if the AIC is lower\n",
    "        if results.aic < best_aic:\n",
    "            print(f'New best model found with AIC: {results.aic}')\n",
    "            best_model = results\n",
    "            best_aic = results.aic\n",
    "    except Exception as e:\n",
    "        print(f'Failed to create VAR model with all columns. Error: {e}')\n",
    "\n",
    "    # if 'Portfolio' in columns_to_drop:, remove it\n",
    "    if 'Portfolio' in columns_to_drop:\n",
    "        columns_to_drop.remove('Portfolio')\n",
    "        print(f'Removing Portfolio from columns_to_drop, leaving these: {columns_to_drop}')\n",
    "\n",
    "    # Iterate through the columns to drop and create a VAR model with the optimal lag order\n",
    "    for i in range(len(columns_to_drop) + 1):\n",
    "        try:\n",
    "            columns = columns_to_drop[:i]\n",
    "            print(f'Creating VAR model with columns dropped: {columns}')\n",
    "            # Drop the specified columns\n",
    "            data_dropped = data.drop(columns=columns)\n",
    "\n",
    "            print(f'After dropping columns, data.keys(): {data_dropped.keys()}\\ndata.head():\\n{data_dropped.head()}\\ndata.tail():\\n{data_dropped.tail()}')\n",
    "            # Create the VAR model\n",
    "            model = VAR(data_dropped)\n",
    "\n",
    "            # Fit the model with the optimal lag order\n",
    "            results = model.fit(ic='aic')\n",
    "            print(f'VAR model results:\\n{results.summary()}')\n",
    "\n",
    "            # Update the best model if the AIC is lower\n",
    "            if results.aic < best_aic:\n",
    "                print(f'New best model found with AIC: {results.aic}')\n",
    "                best_model = results\n",
    "                best_aic = results.aic\n",
    "        except Exception as e:\n",
    "            print(f'Failed to create VAR model with columns dropped: {columns}. Error: {e}')\n",
    "\n",
    "    if best_model is not None:\n",
    "        print(f'Best model AIC: {best_aic}')\n",
    "        print(f'Columns dropped: {columns_to_drop[:i]}')\n",
    "        coefficients = best_model.params\n",
    "        lag_order = best_model.k_ar\n",
    "        return best_model, coefficients, lag_order\n",
    "    else:\n",
    "        print('Failed to create any VAR model.')\n",
    "        return None, None, None\n",
    "    \n",
    "\n",
    "\n",
    "def plot_irf(var_model, periods=10):\n",
    "    irf = var_model.irf(periods=periods)\n",
    "    portfolio_index = var_model.names.index('Portfolio')\n",
    "    data = []\n",
    "    max_impact = 0\n",
    "    max_impact_var = ''\n",
    "\n",
    "    # Find the variable with the maximum cumulative absolute impact on the portfolio\n",
    "    for i, name in enumerate(var_model.names):\n",
    "        if i != portfolio_index:\n",
    "            impact = irf.orth_irfs[:, i, portfolio_index]\n",
    "            cumulative_impact = sum(abs(imp) for imp in impact)\n",
    "            if cumulative_impact > max_impact:\n",
    "                max_impact = cumulative_impact\n",
    "                max_impact_var = name\n",
    "\n",
    "    # Create a trace for each variable's impact on the portfolio\n",
    "    for i, name in enumerate(var_model.names):\n",
    "        if i != portfolio_index:\n",
    "            impact = irf.orth_irfs[:, i, portfolio_index]\n",
    "            color = colorsys.hsv_to_rgb(i / len(var_model.names), 0.5, 0.5)\n",
    "            \n",
    "            if name == max_impact_var:\n",
    "                line_dict = {'color': 'rgb' + str(color), 'width': 3, 'dash': 'dash'}\n",
    "                mode_dict = 'lines+markers'\n",
    "            else:\n",
    "                line_dict = {'color': 'rgb' + str(color), 'width': 1}\n",
    "                mode_dict = 'lines'\n",
    "                \n",
    "            trace = go.Scatter(x=list(range(periods+1)), y=impact, mode=mode_dict, line=line_dict, name=f'Impact of {name} on Portfolio')\n",
    "            data.append(trace)\n",
    "    \n",
    "    # Create the layout for the plot\n",
    "    layout = go.Layout(title='Impulse Response of Portfolio Returns to Shocks in Macro Factors',\n",
    "                       xaxis=dict(title='Period (portfolio return lag in months due to >1 std deviation change in factor)'),\n",
    "                       yaxis=dict(title='Change in Portfolio Returns (%)'))\n",
    "\n",
    "    # Create the figure and plot the traces\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    fig.update_yaxes(tickformat=\".1%\")\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def forecast_var_model(var_model, steps=5):\n",
    "    # Forecast the next steps\n",
    "    forecast = var_model.forecast(var_model.y, steps)\n",
    "\n",
    "    # Find the index of the Portfolio variable\n",
    "    portfolio_index = var_model.names.index('Portfolio')\n",
    "\n",
    "    # Create the forecast series for the portfolio\n",
    "    forecast_portfolio = forecast[:, portfolio_index]\n",
    "\n",
    "    # Create a trace for the forecast\n",
    "    trace = go.Scatter(x=list(range(len(forecast_portfolio))), y=forecast_portfolio, name='Forecast')\n",
    "\n",
    "    # Create the layout for the plot\n",
    "    layout = go.Layout(title='Forecast for Portfolio', xaxis=dict(title='Period'), yaxis=dict(title='Value'))\n",
    "\n",
    "    # Create the figure and plot the trace\n",
    "    fig = go.Figure(data=[trace], layout=layout)\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def calculate_optimal_lag(input_df, factor, maxlag=12):\n",
    "    \"\"\"Compute cross-correlation between portfolio returns and several lagged versions of the factor, and return the lag with the highest absolute cross-correlation\"\"\"\n",
    "    df = input_df.copy()\n",
    "    df = df.dropna(how='any').reset_index(drop=True)\n",
    "    \n",
    "    optimal_lag = 0\n",
    "    max_cross_correlation = 0\n",
    "    for lag in range(-maxlag, maxlag + 1):\n",
    "        cross_correlation = abs(np.correlate(df['Portfolio'], df[factor].shift(lag), mode='valid').mean())\n",
    "        if cross_correlation > max_cross_correlation:\n",
    "            optimal_lag = lag\n",
    "            max_cross_correlation = cross_correlation\n",
    "    return optimal_lag\n",
    "\n",
    "def create_regression_models_v0(returns_data, time_basis, cumulative_performance=False):\n",
    "    monthly_input_data_df = prepare_data(returns_data)\n",
    "    print(f'monthly_input_df index type: {type(monthly_input_data_df.index)}')\n",
    "    \n",
    "    factor_list = get_factor_list(monthly_input_data_df)\n",
    "    print(f'monthly_input_df keys: {monthly_input_data_df.keys()}')\n",
    "    print(f'monthly_input_df data head:\\n{monthly_input_data_df.head()}')\n",
    "\n",
    "    # Initialize dict to store models\n",
    "    regression_models_dict = {}\n",
    "\n",
    "    # Loop through all macro factors and build a regression model for each\n",
    "    for factor in factor_list:\n",
    "        regression_models_dict[factor] = {}\n",
    "        # Create a dataframe for the current factor and the portfolio returns\n",
    "        df_factor = monthly_input_data_df[['Portfolio', factor]].dropna()\n",
    "        \n",
    "        #print(f'creating linear regression model for *{factor}* data:\\n{df_factor.head()}')\n",
    "\n",
    "        # Calculate optimal lag for the current factor - a change in macro factor may take some time to affect the portfolio returns\n",
    "        # The optimal lag is the lag with the highest absolute cross-correlation between the factor and the portfolio returns\n",
    "        optimal_lag = calculate_optimal_lag(df_factor, factor)\n",
    "        \n",
    "        if optimal_lag > 0:\n",
    "            print(f'Optimal lag for {factor} is {optimal_lag}')\n",
    "            df_factor[factor] = df_factor[factor].shift(optimal_lag).dropna()\n",
    "            \n",
    "        # Calculate linear regression models for each factor\n",
    "        regression_model, coefficient, p_value = calculate_linear_regression_model_for_factor(df_factor, factor)\n",
    "\n",
    "        # Store the models, coefficients, and p-values in the dict\n",
    "        regression_models_dict[factor]['linear'] = {\"model\": regression_model, \"coefficient\": coefficient, \"p_value\": p_value, \"optimal_lag\": optimal_lag}\n",
    "       \n",
    "        create_linear_regression_plots(monthly_input_data_df, factor, regression_models_dict, time_basis, cumulative_performance)\n",
    "        \n",
    "    plot_linear_regression_results(regression_models_dict)    \n",
    "\n",
    "    # Use the multivariate model to identify significant factors\n",
    "    multivariate_model, significant_features = calculate_multivariate_analysis(monthly_input_data_df)\n",
    "    regression_models_dict['multivariate'] = {\"model\": multivariate_model, \"significant_features\": significant_features}   \n",
    "    plot_multivariate_results(monthly_input_data_df, multivariate_model, significant_features)\n",
    "    \n",
    "    # Create and store the VAR model separately - only works with stationary data, i.e., the month to month change/returns data\n",
    "    if not cumulative_performance:\n",
    "        try:         \n",
    "            print(f'\\n~~~\\nabout to create var model with monthly_input_df index type: {type(monthly_input_data_df.index)}\\n~~~\\n')       \n",
    "            var_model, coefficients, lag_order = create_var_model(monthly_input_data_df)\n",
    "            if var_model is not None:\n",
    "                regression_models_dict['VAR'] = {\"model\": var_model, \"coefficients\": coefficients, \"lag_order\": lag_order}\n",
    "                plot_irf(var_model, periods=10)  # Plot the impulse response function for 10 periods\n",
    "                forecast_var_model(var_model, steps=5)\n",
    "        except Exception as e:\n",
    "            print(f'VAR model failed to run\\n{e}')\n",
    "    \n",
    "    return regression_models_dict\n",
    "\n",
    "\n",
    "def create_regression_models(returns_data, time_basis, cumulative_performance=False):\n",
    "    monthly_input_data_df = prepare_data(returns_data)\n",
    "    \n",
    "    factor_list = get_factor_list(monthly_input_data_df)\n",
    "\n",
    "    # Initialize dataframes to store models\n",
    "    regression_models_df = pd.DataFrame(columns=['Model Type', 'Factor', 'Model', 'Coefficient', 'P-value', 'Optimal Lag'])\n",
    "    multivariate_models_df = pd.DataFrame(columns=['Model Type', 'Model', 'Significant Features'])\n",
    "    var_models_df = pd.DataFrame(columns=['Model Type', 'Model', 'Coefficients', 'Lag Order'])\n",
    "\n",
    "    # Loop through all macro factors and build a regression model for each\n",
    "    for factor in factor_list:\n",
    "        # Create a dataframe for the current factor and the portfolio returns\n",
    "        df_factor = monthly_input_data_df[['Portfolio', factor]].dropna()\n",
    "        \n",
    "        # Calculate optimal lag for the current factor - a change in macro factor may take some time to affect the portfolio returns\n",
    "        # The optimal lag is the lag with the highest absolute cross-correlation between the factor and the portfolio returns\n",
    "        optimal_lag = calculate_optimal_lag(df_factor, factor)\n",
    "        \n",
    "        if optimal_lag > 0:\n",
    "            df_factor[factor] = df_factor[factor].shift(optimal_lag).dropna()\n",
    "            \n",
    "        # Calculate linear regression models for each factor\n",
    "        regression_model, coefficient, p_value = calculate_linear_regression_model_for_factor(df_factor, factor)\n",
    "\n",
    "        regression_models_df.loc[len(regression_models_df)] = {\n",
    "            'Model Type': 'linear',\n",
    "            'Factor': factor,\n",
    "            'Model': regression_model, \n",
    "            'Coefficient': coefficient, \n",
    "            'P-value': p_value, \n",
    "            'Optimal Lag': optimal_lag}\n",
    "        \n",
    "#        create_linear_regression_plots(monthly_input_data_df, factor, regression_models_df, time_basis, cumulative_performance)\n",
    "        \n",
    "    # Use the multivariate model to identify significant factors\n",
    "    multivariate_model, significant_features = calculate_multivariate_analysis(monthly_input_data_df)\n",
    "\n",
    "    multivariate_models_df.loc[len(multivariate_models_df)] = {\n",
    "        'Model Type': 'multivariate',\n",
    "        'Model': multivariate_model, \n",
    "        'Significant Features': significant_features\n",
    "    }\n",
    "\n",
    "    # Create and store the VAR model separately - only works with stationary data\n",
    "    if not cumulative_performance:\n",
    "        try:         \n",
    "            var_model, coefficients, lag_order = create_var_model(monthly_input_data_df)\n",
    "            if var_model is not None:\n",
    "                var_models_df.loc[len(var_models_df)] = {\n",
    "                    'Model Type': 'VAR',\n",
    "                    'Model': var_model, \n",
    "                    'Coefficients': coefficients, \n",
    "                    'Lag Order': lag_order}\n",
    "#                plot_irf(var_model, periods=10)  # Plot the impulse response function for 10 periods\n",
    "#                forecast_var_model(var_model, steps=5)\n",
    "            print(f'\\n~~~\\nvar model created\\n~~~\\n')\n",
    "            print(f'coefficients:\\n{coefficients}\\n\\n{type(coefficients)}***********')\n",
    "            print(f'lag order:\\n{lag_order}\\n\\n***********')\n",
    "            print(f'var model summary:\\n{var_model.summary()}')\n",
    "        except Exception as e:\n",
    "            print(f'VAR model failed to run\\n{e}')\n",
    "    \n",
    "    return regression_models_df, multivariate_models_df, var_models_df\n",
    "\n",
    "tickers = ['AAPL','AMZN','NVDA','MMC','GOOG','MSFT','BTC-USD','ETH-USD','XOM','BAC','V','GOLD','^GSPC']\n",
    "start_date = '2010-01-01'\n",
    "end_date = datetime.now() - timedelta(1)\n",
    "    \n",
    "regression_models_df, multivariate_models_df, var_models_df = create_regression_models(cumulative_returns_data, 'Monthly', True)\n",
    "regression_models_df, multivariate_models_df, var_models_df  = create_regression_models(returns_data, 'Monthly', False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we're trying to do, essentially, is use economic factors to understand and forecast a portfolio's returns. There are certainly examples of investment firms using similar methods.\n",
    "\n",
    "Let's break this down into five steps:\n",
    "\n",
    "1. Regression Analysis on These Macro Economic Factors vs a Weighted Portfolio of Stocks\n",
    "\n",
    "This first step is crucial in understanding how each factor individually impacts the portfolio returns. Your calculate_linear_regression_models_from_macro_data_per_factor function seems to accomplish this. For each factor, it fits a linear regression model with the portfolio return as the dependent variable and the factor as the independent variable.\n",
    "\n",
    "Just make sure your factors are at the same frequency and aligned by the dates.\n",
    "\n",
    "2. Multivariate Analysis\n",
    "\n",
    "After looking at each factor independently, you are right to consider the interaction between factors using a multivariate analysis.\n",
    "\n",
    "Your function already includes this as well with the \"all_factors\" model. This model uses all factors as independent variables to predict the dependent variable.\n",
    "\n",
    "You may also want to consider checking multicollinearity between the factors using Variance Inflation Factor (VIF) before including all the factors in your multivariate model. If there's high multicollinearity, it may lead to an unstable model where small changes in the data lead to large changes in the model. In that case, you may want to use a subset of the factors or consider dimensionality reduction techniques like PCA.\n",
    "\n",
    "3. Select Factors for Prophet Forecast\n",
    "\n",
    "With the output of the regression analyses, you can examine the coefficients and p-values of the factors to decide which ones are significant in predicting the portfolio returns.\n",
    "\n",
    "You would typically choose factors with a low p-value (p<0.05) indicating statistical significance and a high coefficient absolute value indicating a stronger effect.\n",
    "\n",
    "4. Forecast Macro Indicators & Predict Portfolio Value\n",
    "\n",
    "Once you have selected the significant factors, you can forecast these using your tuned Prophet models.\n",
    "\n",
    "After forecasting the factors, you can use these forecasts as input to the regression model to predict the future value of the portfolio.\n",
    "\n",
    "5. Use Prophet to Predict the Portfolio\n",
    "\n",
    "Finally, you would like to use Prophet to predict the value of the portfolio itself using the macro indicators chosen as regressors. This can be done by fitting a Prophet model on your portfolio data and adding the selected macro indicators as regressors using the add_regressor method.\n",
    "\n",
    "\n",
    "Data Preparation: Before feeding data to a model, it needs to be prepared in a manner that's consistent with the model's expectations. This includes checking for missing values and possibly imputing them, scaling the data if necessary, and finally transforming the data into a format suitable for time series forecasting. In your case, this would mean having rows for each day (even if the macroeconomic data doesn't change on a daily basis), and columns for your independent variables (the macroeconomic indicators) and your dependent variable (the portfolio returns).\n",
    "\n",
    "Feature Engineering: You could include lagged versions of your independent variables as new features. For instance, you could include the GDP from one month ago, two months ago, etc., as new columns in your dataset. This could help your model understand the relationship between past values of the independent variables and the current value of the dependent variable.\n",
    "\n",
    "Model Selection: There are a number of models you can choose from for your forecasting. ARIMA models and variants thereof (like SARIMA, which accounts for seasonality) are traditional choices for this kind of task, but you could also use machine learning models like Random Forests, Support Vector Regression, or even deep learning models like LSTMs or 1D Convolutional Neural Networks. Ensemble methods, where you combine the predictions of multiple models, can also be very effective.\n",
    "\n",
    "Model Training: Train your selected model on your training data.\n",
    "\n",
    "Hyperparameter Tuning: Depending on the model you've chosen, there may be a number of hyperparameters that need to be set. You can use grid search or random search methods to find the combination of hyperparameters that yields the best performance on your validation set.\n",
    "\n",
    "Evaluation: Evaluate the performance of your model on your test set. This gives you an unbiased estimate of how your model is likely to perform on unseen data.\n",
    "\n",
    "Forecasting: Use your trained model to make forecasts for the next 365 days. Given that you want to make forecasts for multiple periods, you could either train a new model for each period (using all the data up to that period), or you could use a rolling forecast origin method, where you continually update your forecasts as new data becomes available.\n",
    "\n",
    "Handling Seasonality: Models like SARIMA or Prophet (from Facebook) can handle seasonality internally. If you're using a model that doesn't, you may need to manually account for it in your data preparation step, possibly by detrending and deseasonalizing your data.\n",
    "\n",
    "Model Updating: Given the nature of financial data, the relationships between variables may change over time. You should plan to periodically retrain your model with the most recent data to keep its performance optimal.\n",
    "\n",
    "Uncertainty Estimation: Finally, it's important to have some measure of the uncertainty around your forecasts. Some models can provide this automatically (e.g., ARIMA, Prophet), but for others you might need to use methods like bootstrapping to generate prediction intervals.\n",
    "\n",
    "\n",
    "## the data:\n",
    "monthly_returns = {'Portfolio': portfolio_monthly_returns, 'S&P500': sp500_monthly_returns, 'Macro': mom_macro_data}\n",
    "quarterly_returns = {'Portfolio': portfolio_quarterly_returns, 'S&P500': sp500_quarterly_returns, 'Macro': qoq_macro_data}\n",
    "annual_returns = {'Portfolio': portfolio_annual_returns, 'S&P500': sp500_annual_returns, 'Macro': yoy_macro_data}\n",
    "\n",
    "cumulative_monthy_returns = {'Portfolio': portfolio_cumulative_monthly_returns, 'S&P500': sp500_cumulative_monthly_returns, 'Macro': monthly_macro_data}\n",
    "cumulative_quarterly_returns = {'Portfolio': portfolio_cumulative_quarterly_returns, 'S&P500': sp500_cumulative_quarterly_returns, 'Macro': quarterly_macro_data} \n",
    "cumulative_annual_returns = {'Portfolio': portfolio_cumulative_annual_returns, 'S&P500': sp500_cumulative_annual_returns, 'Macro': yoy_macro_data}        \n",
    "\n",
    "## tuned hyperparameter file\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "date = datetime.now().strftime(\"%Y%m%d\")\n",
    "print(f'date: {date}')\n",
    "\n",
    "cur_tuned_params_df = pd.read_csv(f'tuned_macro_hyperparameters_20230605.csv', index_col=[0, 1])\n",
    "\n",
    "print(f'cur_tuned_params_df:\\n{cur_tuned_params_df}')\n",
    "\n",
    "def load_latest_tuned_hyperparameters():\n",
    "    # List all files that begin with \"tuned_macro_hyperparameters\"\n",
    "    files = glob.glob('tuned_macro_hyperparameters_*.csv')\n",
    "\n",
    "    # If no files found, return None\n",
    "    if not files:\n",
    "        return None\n",
    "\n",
    "    # Sort files by date\n",
    "    files.sort(key=os.path.getmtime, reverse=True)\n",
    "\n",
    "    # Load the most recent file\n",
    "    latest_file = files[0]\n",
    "    df = pd.read_csv(latest_file, index_col=[0, 1])\n",
    "\n",
    "    return df\n",
    "\n",
    "cur_tuned_params_df = load_latest_tuned_hyperparameters()\n",
    "print(f'cur_tuned_params_df:\\n{cur_tuned_params_df}')\n",
    "\n",
    "# TODO: flag the tuned parms as good or needing more work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "# enable absolute paths transversal (from notebooks folder to src folder)\n",
    "parent_dir = os.path.abspath('..')\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "    \n",
    "import glob\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from pypfopt import expected_returns, EfficientFrontier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import src.utils as utils\n",
    "import src.macro.calculate as calculate\n",
    "import src.macro.plot as plot\n",
    "\n",
    "tickers = ['AAPL','AMZN','NVDA','MMC','GOOG','MSFT','BTC-USD','ETH-USD','XOM','BAC','V','GOLD','^GSPC']\n",
    "start_date = '2014-01-01'\n",
    "end_date = datetime.now() - timedelta(1)\n",
    "\n",
    "#cur_tuned_params_dict = load_latest_tuned_hyperparameters()\n",
    "#tuned_macro_hyperparameters_tuned_hyper_parms_w_init_2190_period_68.4375_horizon_136.875_20230608.json\n",
    "def load_tuned_hyperparameters(file_name):\n",
    "\n",
    "    df = pd.read_json(file_name)\n",
    "\n",
    "    return df\n",
    "\n",
    "cur_tuned_params_dict = load_tuned_hyperparameters('tuned_macro_hyperparameters_tuned_hyper_parms_w_init_2190_period_68.4375_horizon_136.875_20230608.json')\n",
    "\n",
    "# monthly_returns = {'Portfolio': portfolio_monthly_returns, 'S&P500': sp500_monthly_returns, 'Macro': mom_change_in_macro_data} # compare macro with *cumulative* monthly returns\n",
    "\n",
    "returns_data, cumulative_returns_data = get_combined_returns_data(tickers, start_date, end_date)\n",
    "print(f\"monthly portfolio returns {returns_data['Monthly']['Portfolio'].head()}\")\n",
    "print(f\"monthly sp500 returns {returns_data['Monthly']['S&P500'].head()}\")\n",
    "print(f\"monthly macro keys {returns_data['Monthly']['Macro'].keys()}\")\n",
    "print(f\"monthly macro CPI {returns_data['Monthly']['Macro']['CPI'].head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from statsmodels.api import OLS\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import warnings\n",
    "import plotly.graph_objects as go\n",
    "import plotly.subplots as sp\n",
    "import itertools\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def create_altair_plots(df, factor, regression_model, factor_forecast_model, months_to_forecast):\n",
    "    monthly_portfolio_forecast, cumulative_monthly_portfolio_forecast = forecast_portfolio_from_regression_based_on_predicted_factor(factor, regression_model, factor_forecast_model, months_to_forecast)\n",
    "    \n",
    "    # Define the base plot\n",
    "    base = alt.Chart(df.reset_index()).encode(x='index:T')\n",
    "    \n",
    "    # Create the Returns plot\n",
    "    returns_layer = base.mark_line().encode(\n",
    "        y='Portfolio',\n",
    "        color=alt.value('royalblue')\n",
    "    ) + base.mark_line().encode(\n",
    "        y='S&P500',\n",
    "        color=alt.value('grey')\n",
    "    ) + base.mark_line().encode(\n",
    "        y=factor,\n",
    "        color=alt.value('black')\n",
    "    )\n",
    "    \n",
    "    # Create the Regression plot\n",
    "    X = add_constant(df[[factor]])\n",
    "    fitted_values = regression_model.predict(X)\n",
    "    regression_layer = base.mark_point().encode(\n",
    "        y='Portfolio',\n",
    "        x=factor\n",
    "    ) + base.mark_line().encode(\n",
    "        y=alt.Y('fitted_values', title='Fitted Line'),\n",
    "        x=factor\n",
    "    )\n",
    "    \n",
    "    # Create the Residuals plot\n",
    "    residuals = df[\"Portfolio\"] - fitted_values\n",
    "    residuals_layer = base.mark_line().encode(\n",
    "        y=alt.Y('residuals', title='Linear Regression Residuals')\n",
    "    )\n",
    "\n",
    "    # Create the Forecast plot\n",
    "    forecast_layer = alt.Chart(monthly_portfolio_forecast.reset_index()).mark_line().encode(\n",
    "        x='index:T',\n",
    "        y=factor\n",
    "    ) + alt.Chart(monthly_portfolio_forecast.reset_index()).mark_line().encode(\n",
    "        x='index:T',\n",
    "        y='Portfolio'\n",
    "    )\n",
    "\n",
    "    # Create the Cumulative Returns Forecast plot\n",
    "    cumulative_layer = alt.Chart(cumulative_monthly_portfolio_forecast.reset_index()).mark_line().encode(\n",
    "        x='index:T',\n",
    "        y=factor\n",
    "    ) + alt.Chart(cumulative_monthly_portfolio_forecast.reset_index()).mark_line().encode(\n",
    "        x='index:T',\n",
    "        y='Portfolio'\n",
    "    )\n",
    "\n",
    "    # Concatenate the plots and customize\n",
    "    chart = alt.hconcat(returns_layer, regression_layer, residuals_layer, forecast_layer, cumulative_layer).properties(\n",
    "        title=f'Return, Regression, Residuals, Forecast, and Cumulative Forecast for {factor}'\n",
    "    )\n",
    "    \n",
    "    # Display the plot\n",
    "    chart.display()\n",
    "    \n",
    "def plot_multivariate_results(input_df, multivariate_model, significant_features):\n",
    "    fig = go.Figure(data=[go.Bar(name='Coefficient', x=multivariate_model.params.index, y=multivariate_model.params.values), \n",
    "                          go.Bar(name='p-value', x=multivariate_model.pvalues.index, y=multivariate_model.pvalues.values)])\n",
    "    fig.update_layout(barmode='group', title_text='Multivariate Regression Results')\n",
    "    fig.show()\n",
    "\n",
    "    # Scatter plots for each significant feature\n",
    "    for feature in significant_features:\n",
    "        # Calculate the OLS trendline\n",
    "        m, b = np.polyfit(input_df[feature], input_df['Portfolio'], 1)\n",
    "\n",
    "        fig2 = go.Figure()\n",
    "        fig2.add_trace(go.Scatter(x=input_df[feature], y=input_df['Portfolio'], mode='markers', name='observations'))\n",
    "        fig2.add_trace(go.Scatter(x=input_df[feature], y=m*input_df[feature] + b, mode='lines', name='OLS trendline'))\n",
    "        fig2.update_layout(title=f'Portfolio Returns vs {feature}', xaxis_title=feature, yaxis_title='Portfolio Returns')\n",
    "        fig2.show()\n",
    "\n",
    "def plot_linear_regression_results(regression_model_dict):\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    for factor, result in regression_model_dict.items():\n",
    "        fig.add_trace(\n",
    "            go.Bar(name=f'Coefficient - {factor}', x=[factor], y=[result['coefficient']], marker_color='lightblue')\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Bar(name=f'p-value - {factor}', x=[factor], y=[result['p_value']], marker_color='lightsalmon')\n",
    "        )\n",
    "\n",
    "    fig.update_layout(barmode='group', title_text='Linear Regression Results')\n",
    "    fig.show()\n",
    "    \n",
    "# Create a function to visualize backtesting results\n",
    "def plot_backtesting_results(mse, mae, forecast, holdout):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Plot the actual data\n",
    "    fig.add_trace(go.Scatter(x=holdout.index, y=holdout['Portfolio'], mode='lines', name='Actual Portfolio'))\n",
    "\n",
    "    # Plot the forecasted data\n",
    "    fig.add_trace(go.Scatter(x=forecast.ds, y=forecast.yhat, mode='lines', name='Predicted Portfolio', line=dict(color='royalblue')))\n",
    "\n",
    "    # Plot the confidence interval\n",
    "    fig.add_trace(go.Scatter(x=forecast.ds, y=forecast.yhat_lower, fill='tonexty', mode='lines', fillcolor='rgba(68,68,68,0.3)', line_color='transparent', showlegend=False))\n",
    "    fig.add_trace(go.Scatter(x=forecast.ds, y=forecast.yhat_upper, fill='tonexty', mode='lines', fillcolor='rgba(68,68,68,0.3)', line_color='transparent', showlegend=False))\n",
    "\n",
    "    # Add MSE and MAE as annotations\n",
    "    fig.add_annotation(\n",
    "        x=0.05,\n",
    "        y=0.95,\n",
    "        xref=\"paper\",\n",
    "        yref=\"paper\",\n",
    "        text=f\"MSE: {mse:.3f}, MAE: {mae:.3f}\",\n",
    "        showarrow=False,\n",
    "        font=dict(\n",
    "            size=10\n",
    "        ),\n",
    "        bgcolor=\"rgba(255,255,255,0.8)\"\n",
    "    )\n",
    "\n",
    "    fig.update_layout(title='Backtesting Results', xaxis_title='Date', yaxis_title='Portfolio Value')\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "    \n",
    "def plot_prophet_forecast(forecast):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Historical data\n",
    "    fig.add_trace(go.Scatter(x=forecast['ds'], y=forecast['y'], mode='lines', name='Historical Returns', line=dict(color='royalblue')))\n",
    "\n",
    "    # Forecasted data\n",
    "    fig.add_trace(go.Scatter(x=forecast['ds'], y=forecast['yhat'], mode='lines', name='Forecasted Returns', line=dict(color='darkorange')))\n",
    "    fig.add_trace(go.Scatter(x=forecast['ds'], y=forecast['yhat_lower'], mode='lines', name='Lower Bound', line=dict(color='grey'), fill='tonexty'))\n",
    "    fig.add_trace(go.Scatter(x=forecast['ds'], y=forecast['yhat_upper'], mode='lines', name='Upper Bound', line=dict(color='grey'), fill='tonexty'))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title='Prophet Model Forecast of Portfolio Returns',\n",
    "        xaxis_title='Date',\n",
    "        yaxis_title='Returns',\n",
    "        hovermode='x',\n",
    "        template='plotly_dark'\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "    \n",
    "    \n",
    "def create_comparison_regress_forecast_plots(df, factor, regression_model, factor_forecast_model, months_to_forecast):\n",
    "\n",
    "    fig = sp.make_subplots(rows=1, cols=5, subplot_titles=(\"Returns\", \"Regression\", \"Residuals\", \"Forecast\"), specs=[[{'secondary_y': True}, {}, {}, {}, {}]])\n",
    "\n",
    "    # plot the original data to compare portfolio vs benchmark vs macro economic factor\n",
    "    fig.add_trace(go.Scatter(x=df.index, y=df[\"Portfolio\"], mode='lines', name='Portfolio', line=dict(color='royalblue')), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=df.index, y=df[\"S&P500\"], mode='lines', name='S&P500', line=dict(color='grey')), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=df.index, y=df[factor], mode='lines', name=factor, line=dict(dash='dot')), secondary_y=True, row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Returns\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=factor, secondary_y=True, row=1, col=1)\n",
    "    \n",
    "    # Plot the linear regression results of the monthly portfolio returns vs the monthly change in macroeconomic factor\n",
    "    X = add_constant(df[[factor]])\n",
    "    fitted_values = regression_model.predict(X)\n",
    "    fig.add_trace(go.Scatter(x=df[factor], y=df[\"Portfolio\"], mode='markers', name=f'{factor} (x) vs Returns (y)'), row=1, col=2)\n",
    "    fig.add_trace(go.Scatter(x=df[factor], y=fitted_values, mode='lines', name='Fitted line'), row=1, col=2)\n",
    "    fig.update_xaxes(title_text=f'{factor} Monthly Change', tickformat=\".2%\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"Returns\", tickformat=\".2%\", row=1, col=2)\n",
    "    \n",
    "    # Plot the linear regression residuals\n",
    "    residuals = df[\"Portfolio\"] - fitted_values\n",
    "    fig.add_trace(go.Scatter(x=df.index, y=residuals, mode='lines', name='Linear Regression Residuals'), row=1, col=3)\n",
    "    \n",
    "    # forecast the portfolio returns based on the linear regression prediction model leveraging the prophet forecast of the future monthly change in the macroeconomic factor\n",
    "    monthly_portfolio_forecast, cumulative_monthly_portfolio_forecast = forecast_portfolio_from_regression_based_on_predicted_factor(factor, regression_model, factor_forecast_model, months_to_forecast)\n",
    "        \n",
    "    # create a plot of the linear regression prediction of monthly returns based on Prophet's forecast of the future monthly change in the macroeconomic factor\n",
    "    fig.add_trace(go.Scatter(x=monthly_portfolio_forecast.index, y=monthly_portfolio_forecast[f'{factor}'], mode='lines', name=f'{factor} (Time Series Prediction)', line=dict(color='red')), row=1, col=4)\n",
    "    fig.add_trace(go.Scatter(x=monthly_portfolio_forecast.index, y=monthly_portfolio_forecast, mode='lines', name='Portfolio Monthly Returns (Linear Regression Prediction)', line=dict(color='red')), row=1, col=4)\n",
    "\n",
    "    # create a plot of the cumulative returns based on Prophet's forecast of the future monthly change in the macroeconomic factor\n",
    "    fig.add_trace(go.Scatter(x=cumulative_monthly_portfolio_forecast.index, y=cumulative_monthly_portfolio_forecast[f'{factor}'], mode='lines', name=f'{factor} Cumulative Time Series Forecast',  line=dict(dash='dot')), row=1, col=5)\n",
    "    fig.add_trace(go.Scatter(x=cumulative_monthly_portfolio_forecast.index, y=cumulative_monthly_portfolio_forecast['Portfolio'], mode='lines', name='Cumulative Portfolio Returns Forecast (Linear Regression Prediction)', line=dict(color='royalblue')), row=1, col=5)\n",
    "\n",
    "    fig.update_layout(title_text=f'Portfolio Returns vs {factor}, Linear Regression of Portfolio vs {factor}, and Time Series Forecast for {factor} with Linear Regression Prediction of Portfolio Returns', showlegend=False)\n",
    "    fig.show()\n",
    "    \n",
    "\n",
    "    \n",
    "def validate_data(data, trace=None):\n",
    "    if type(data) == pd.DataFrame:\n",
    "        nan_columns = data.columns[data.isna().any()].tolist()\n",
    "        inf_columns = data.columns[np.isinf(data).any()].tolist()\n",
    "\n",
    "        print(f\"{trace}: Columns with NaN values: {nan_columns}\")\n",
    "        print(f\"{trace}: Columns with Inf values: {inf_columns}\")\n",
    "    else:\n",
    "        # must be a pd.Series, validate that no values are NaN or Inf\n",
    "        if data.isna().any():\n",
    "            print(f\"{trace}: Series has NaN values\")\n",
    "        if np.isinf(data).any():\n",
    "            print(f\"{trace}: Series has Inf values\")\n",
    "    \n",
    "# Aligning the dataframes\n",
    "def align_dataframes(dfs):\n",
    "    # Get the common datetime index\n",
    "    common_index = dfs[0].index\n",
    "    for df in dfs[1:]:\n",
    "        common_index = common_index.intersection(df.index)\n",
    "    \n",
    "    # Align all dataframes to the common index\n",
    "    aligned_dfs = [df.loc[common_index] for df in dfs]\n",
    "    return aligned_dfs\n",
    "\n",
    "def prepare_data(returns_data):\n",
    "    portfolio_returns = returns_data['Monthly']['Portfolio'].to_frame(name='Portfolio')\n",
    "    sp500_returns = returns_data['Monthly']['S&P500'].to_frame(name='S&P500')\n",
    "\n",
    "    # concat sp500 with portfolio returns\n",
    "    portfolio_returns = pd.concat([portfolio_returns, sp500_returns], axis=1)\n",
    "\n",
    "    # Loop through all macro factors and add to DataFrame\n",
    "    for factor_name, factor_df in returns_data['Monthly']['Macro'].items():\n",
    "        factor_df = factor_df.rename(factor_name)  # Rename the series\n",
    "        portfolio_returns = pd.concat([portfolio_returns, factor_df], axis=1)\n",
    "\n",
    "    # Use align_dataframes to ensure the data is properly aligned\n",
    "    aligned_data = align_dataframes([portfolio_returns])\n",
    "\n",
    "    aligned_data[0] = aligned_data[0].dropna()\n",
    "\n",
    "    return aligned_data[0]  # align_dataframes returns a list, so we take the first element\n",
    "\n",
    "\"\"\"\n",
    "The check_multicollinearity() function calculates the Variance Inflation Factor (VIF) for each macro factor. \n",
    "VIF measures the correlation between each factor and all other factors. If a factor's VIF exceeds a certain \n",
    "threshold (in this case, 5), it indicates high multicollinearity.\n",
    "\"\"\"\n",
    "def check_multicollinearity(df, vif_threshold=5):\n",
    "    variables = df.columns\n",
    "    vif_df = pd.DataFrame()\n",
    "    vif_df[\"VIF\"] = [variance_inflation_factor(df[variables].values, df.columns.get_loc(var)) for var in df.columns]\n",
    "    vif_df[\"Features\"] = variables\n",
    "    while vif_df[vif_df['VIF'] > vif_threshold].any(axis=None):\n",
    "        remove = vif_df.sort_values('VIF',ascending=0)['Features'][:1]\n",
    "        df.drop(remove,axis=1,inplace=True)\n",
    "        variables = df.columns\n",
    "        vif_df = pd.DataFrame()\n",
    "        vif_df[\"VIF\"] = [variance_inflation_factor(df[variables].values, df.columns.get_loc(var)) for var in df.columns]\n",
    "        vif_df[\"Features\"] = variables\n",
    "    return df\n",
    "\n",
    "def get_factor_list(df):\n",
    "    factor_list = list(df.columns)\n",
    "    factor_list.remove('Portfolio')\n",
    "    factor_list.remove('S&P500')\n",
    "    return factor_list\n",
    "\n",
    "def calculate_linear_regression_model_for_factor(df, factor):\n",
    "    X = df[[factor]]\n",
    "    y = df['Portfolio']\n",
    "    X2 = add_constant(X)\n",
    "    model = OLS(y, X2).fit()\n",
    "    coefficient = model.params[factor]\n",
    "    p_value = model.pvalues[factor]\n",
    "    return model, coefficient, p_value\n",
    "\n",
    "def calculate_multivariate_analysis(df):\n",
    "    X = df[get_factor_list(df)]  \n",
    "    y = df['Portfolio']\n",
    "    \n",
    "    model = OLS(y, add_constant(X)).fit()\n",
    "    \n",
    "    # Extract the significant features based on p-values\n",
    "    significant_features = model.pvalues[model.pvalues < 0.05].index.tolist()\n",
    "    \n",
    "    if 'const' in significant_features:\n",
    "        significant_features.remove('const')\n",
    "        \n",
    "    return model, significant_features\n",
    "\n",
    "def tune_hyperparameters_for_portfolio_forecast(df, horizon):\n",
    "   \n",
    "    param_grid = {  \n",
    "        'changepoint_prior_scale': [0.001, 0.005, 0.01, 0.05, 0.1, 0.25, 0.5],\n",
    "        'seasonality_prior_scale': [0.01, 0.1, 1.0, 5.0, 10.0],\n",
    "        'seasonality_mode': ['additive', 'multiplicative'],\n",
    "    }\n",
    "    # Generate all combinations of parameters\n",
    "    all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "    \n",
    "    # Generate all combinations of parameters\n",
    "    all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "    rmses = []  # Store the RMSEs for each params here\n",
    "    smapes = []  # Store the sMAPEs for each params here\n",
    "    coverages = []  # Store the Coverages for each params here\n",
    "    \n",
    "    # Use cross validation to evaluate all parameters\n",
    "    for params in all_params:\n",
    "        try:\n",
    "            m = Prophet(**params).fit(df)  # Fit model with given params\n",
    "            df_cv = cross_validation(m, horizon=f'{horizon} days', parallel=\"processes\")\n",
    "            df_p = performance_metrics(df_cv, rolling_window=1)\n",
    "            rmses.append(df_p['rmse'].values[0])\n",
    "            smapes.append(df_p['smape'].values[0])\n",
    "            coverages.append(df_p['coverage'].values[0])\n",
    "        except Exception as e:\n",
    "            # print the exception\n",
    "            print(f\"Exception {e} in tuning hyper parms parameter: \", params)\n",
    " \n",
    "    # Find the best parameters - use smape for now\n",
    "    best_params_rmse = all_params[np.argmin(rmses)]\n",
    "    best_params_smape = all_params[np.argmin(smapes)]\n",
    "    best_params_coverage = all_params[np.argmax(coverages)]\n",
    "\n",
    "    return best_params_smape\n",
    "\n",
    "# Prophet Model\n",
    "def build_prophet_model_for_portfolio(input_data, significant_factors, factor_forecast_models_dict, months_to_forecast):\n",
    "\n",
    "    df = input_data['Portfolio']\n",
    "    df = df.reset_index()\n",
    "    df.columns = ['ds', 'y']\n",
    "    #print(f'prophet portfolio model input data shape: {df.head()}')   \n",
    "     \n",
    "    # tune hyper parameters and do cross validations to select the optimal parameters based on smape\n",
    "    hyperparameters = tune_hyperparameters_for_portfolio_forecast(df, int(months_to_forecast/10))\n",
    "    \n",
    "    model = Prophet(**hyperparameters)\n",
    "    \n",
    "    # use the forecast_models_dict to select the significant factors as regressors\n",
    "    for factor in significant_factors:\n",
    "        regressor = factor_forecast_models_dict[factor]['forecast'][['ds', 'yhat']]\n",
    "        # ensure the data is in the correct format and dates aligned\n",
    "        regressor.columns = ['ds', factor]\n",
    "        model.add_regressor(factor)\n",
    "    \n",
    "    # build and fit the model to the\n",
    "    model.fit(df)\n",
    "    \n",
    "    # define the period for which we want a prediction - most data is monthly, use MS for month start\n",
    "    future = model.make_future_dataframe(periods=months_to_forecast, freq='MS')\n",
    "    \n",
    "    # merge the future data from each regressor's Prophet forecast with the main 'future' DataFrame\n",
    "    for factor in significant_factors:\n",
    "        future = future.merge(forecast_models_dict[factor]['forecast'][['ds', 'yhat']], on='ds', how='left')\n",
    "        future = future.rename(columns={'yhat': factor})\n",
    "    \n",
    "    # use the model to make a forecast\n",
    "    forecast = model.predict(future)\n",
    "    \n",
    "    return model, forecast\n",
    "\n",
    "# Define the forecast function\n",
    "def build_prophet_forecast_for_factor(df, periods, data_frequency, hyperparameters):\n",
    "    \n",
    "    #print(f'prophet_forecast df:\\n{df.head()}')\n",
    "    #print(f'prophet_forecast df:\\n{df.keys()}')\n",
    "    df = df.reset_index()\n",
    "    df.columns = ['ds', 'y']\n",
    "    df.dropna(inplace=True)\n",
    "    #print(f'prophet_forecast df:\\n{df.head()}')\n",
    "    #print(f'prophet_forecast df:\\n{df.keys()}')\n",
    "            \n",
    "    # Check for missing values\n",
    "    if df['y'].isna().any():\n",
    "        print(\"WARNING: The 'y' column contains missing values. These will be dropped.\")\n",
    "        df = df.dropna()\n",
    "\n",
    "    # Check for non-numeric values\n",
    "    if df['y'].apply(lambda x: not isinstance(x, (int, float))).any():\n",
    "        print(\"WARNING: The 'y' column contains non-numeric values. These cannot be used in the model.\")\n",
    "    \n",
    "    # Check for zero values\n",
    "    if (df['y'] == 0).any():\n",
    "        print(\"WARNING: The 'y' column contains zero values. These can cause problems for the model.\")\n",
    "    \n",
    "    # Check for extreme values\n",
    "    if df['y'].max() > 1e6 or df['y'].min() < -1e6:\n",
    "        print(\"WARNING: The 'y' column contains very large or very small values. These can cause problems for the model.\")\n",
    "\n",
    "    # define the model\n",
    "    model = Prophet(changepoint_prior_scale=hyperparameters['changepoint_prior_scale'], \n",
    "                    seasonality_prior_scale=hyperparameters['seasonality_prior_scale'], \n",
    "                    seasonality_mode=hyperparameters['seasonality_mode'])\n",
    "       \n",
    "    # fit the model\n",
    "    model.fit(df)\n",
    "    \n",
    "    # define the period for which we want a prediction - most data is monthly, use MS for month start\n",
    "    future = model.make_future_dataframe(periods=periods, freq=data_frequency)\n",
    "    \n",
    "    # use the model to make a forecast\n",
    "    forecast = model.predict(future)\n",
    "    \n",
    "    return model, forecast\n",
    "\n",
    "# Model Evaluation\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    return mse, mae\n",
    "\n",
    "# Backtest Model\n",
    "def backtest_model(df, train_size, model):\n",
    "    # Split the data\n",
    "    train = df[:train_size]\n",
    "    holdout = df[train_size:]\n",
    "\n",
    "    # Make predictions\n",
    "    future = model.make_future_dataframe(periods=len(holdout), freq='MS')\n",
    "    forecast = model.predict(future)  # Adjusted line\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse, mae = evaluate_model(holdout['Portfolio'], forecast['yhat'])\n",
    "    return mse, mae, forecast, holdout  # Return forecast and holdout for visualization\n",
    "\n",
    "def forecast_portfolio_from_regression_based_on_predicted_factor(factor, regression_model, forecast_model, months_to_forecast):\n",
    "\n",
    "    # Predict the factor\n",
    "    future_factor = forecast_model.predict(forecast_model.make_future_dataframe(periods=months_to_forecast, freq='MS'))\n",
    "\n",
    "    # Add the predicted factor values into the portfolio DataFrame\n",
    "    y = future_factor['yhat'].dropna()\n",
    "    dates = future_factor['ds']  # Assuming 'ds' is a column with dates\n",
    "\n",
    "    # Predict the portfolio based on the predicted factor\n",
    "    X = add_constant(y)\n",
    "    portfolio_pred = regression_model.predict(X)\n",
    "    \n",
    "    monthly_forecast_df = pd.DataFrame({'Portfolio': portfolio_pred, f'{factor}': y})\n",
    "    monthly_forecast_df.set_index(dates, inplace=True)\n",
    "                \n",
    "    cumulative_monthly_returns = (1 + portfolio_pred).cumprod()\n",
    "    cumulative_monthly_returns = cumulative_monthly_returns.rename('Portfolio')\n",
    "    \n",
    "    cumulative_factor_value = (1 + y).cumprod()\n",
    "    cumulative_factor_value = cumulative_factor_value.rename(factor)\n",
    "\n",
    "    # Build the forecast DataFrame - what is the dateindex set to?\n",
    "    cumulative_forecast_df = pd.DataFrame({'Portfolio': cumulative_monthly_returns, f'{factor}': cumulative_factor_value})\n",
    "    cumulative_forecast_df.set_index(dates, inplace=True)\n",
    "\n",
    "    return monthly_forecast_df, cumulative_forecast_df\n",
    "\n",
    "def create_linear_regression_plots_v0(df, factor, linear_regression_model, factor_forecast_model, months_to_forecast):\n",
    "    X = df[[factor]]\n",
    "    y = df['Portfolio']\n",
    "    X2 = add_constant(X)\n",
    "    predictions = linear_regression_model.predict(X2)\n",
    "    residuals = y - predictions\n",
    "\n",
    "    # Intercept and slope for the annotation\n",
    "    intercept = linear_regression_model.params['const']\n",
    "    slope = linear_regression_model.params[factor]\n",
    "    \n",
    "    #monthly_forecast_df, cumulative_forecast_df = forecast_portfolio_from_regression_based_on_predicted_factor(factor, linear_regression_model, factor_forecast_model, months_to_forecast)\n",
    "\n",
    "    # Initialize subplots\n",
    "    fig = sp.make_subplots(rows=1, cols=4, subplot_titles=(\"Portfolio vs SP500 vs Factor\", \"Predicted vs Actual Values\", \"Residuals vs Predicted Values\"),  specs=[[{'secondary_y': True}, {'secondary_y': True}, {}, {'secondary_y': True}]])\n",
    "    \n",
    "    # Subplot 1: Portfolio vs SP500 vs Factor\n",
    "    fig.add_trace(go.Scatter(x=df.index, y=df[\"Portfolio\"], mode='lines', name='Portfolio', line=dict(color='royalblue')), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=df.index, y=df[\"S&P500\"], mode='lines', name='S&P500', line=dict(color='grey')), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=df.index, y=df[factor], mode='lines', name=factor, line=dict(dash='dot')), secondary_y=True, row=1, col=1)\n",
    "    \n",
    "    fig.update_yaxes(title_text=\"Returns\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=factor, secondary_y=True, row=1, col=1)\n",
    "    \n",
    "    # Subplot 2: Predicted vs Actual values \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x = y,\n",
    "            y = predictions,\n",
    "            mode = 'markers',\n",
    "            marker=dict(\n",
    "                size=10,\n",
    "                color='rgba(152, 0, 0, .8)'\n",
    "            ),\n",
    "            name='Predicted vs Actual'\n",
    "        ), row=1, col=2\n",
    "    )\n",
    "    # Predicted vs. Actual Portfolio Returns with Future Forecast\n",
    "    #fig.add_trace(go.Scatter(x=monthly_forecast_df.index, y=monthly_forecast_df[\"Portfolio\"], mode='lines', name='Portfolio Forecast', line=dict(color='orange')), row=1, col=2)\n",
    "    # Factor Forecasts\n",
    "    #fig.add_trace(go.Scatter(x=monthly_forecast_df.index, y=monthly_forecast_df[factor], mode='lines', name=f'{factor} Forecast', line=dict(color='green')), secondary_y=True, row=1, col=2)\n",
    "    \n",
    "    # Fitted line\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x = y,\n",
    "            y = intercept + slope * y,\n",
    "            mode = 'lines',\n",
    "            line = dict(color='red', width=2),\n",
    "            name='Fitted line'\n",
    "        ), row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # Subplot 3: Residuals vs Predicted Values\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x = predictions,\n",
    "            y = residuals,\n",
    "            mode = 'markers',\n",
    "            marker=dict(\n",
    "                size=10,\n",
    "                color='rgba(152, 0, 0, .8)'\n",
    "            ),\n",
    "            name='Residuals'\n",
    "        ), row=1, col=3\n",
    "    )\n",
    "\n",
    "    # Adding a horizontal line at y=0\n",
    "    fig.add_shape(\n",
    "        type='line',\n",
    "        line=dict(\n",
    "            color='grey',\n",
    "            width=2,\n",
    "            dash='dash'),\n",
    "        x0=min(predictions),\n",
    "        x1=max(predictions),\n",
    "        y0=0,\n",
    "        y1=0,\n",
    "        row=1,\n",
    "        col=3\n",
    "    )\n",
    "    \n",
    "    # Subplot 4: Cumulative Returns with subplot title\n",
    "    #fig.add_trace(go.Scatter(x=cumulative_forecast_df.index, y=cumulative_forecast_df['Portfolio'], mode='lines', name='Cumulative Portfolio Returns', line=dict(color='purple')), row=1, col=4)\n",
    "    #fig.add_trace(go.Scatter(x=cumulative_forecast_df.index, y=cumulative_forecast_df[factor], mode='lines', name=f'Cumulative {factor}', line=dict(color='cyan')), secondary_y=True, row=1, col=4)\n",
    "    fig.update_yaxes(title_text=\"Cumulative Returns\", row=1, col=4)\n",
    "    fig.update_yaxes(title_text=f\"Cumulative {factor}\", secondary_y=True, row=1, col=4)\n",
    "\n",
    "    # Annotations for R-squared and the function's equation\n",
    "    fig.add_annotation(\n",
    "        x=0.05,\n",
    "        y=0.95,\n",
    "        xref=\"paper\",\n",
    "        yref=\"paper\",\n",
    "        text=f\"R-squared = {linear_regression_model.rsquared:.3f}\",\n",
    "        showarrow=False,\n",
    "        font=dict(\n",
    "            size=8\n",
    "        ),\n",
    "        xshift=-25  # adjust this value to move annotation left or right\n",
    "    )\n",
    "\n",
    "    fig.add_annotation(\n",
    "        x=0.05,\n",
    "        y=0.90,\n",
    "        xref=\"paper\",\n",
    "        yref=\"paper\",\n",
    "        text=f\"f(x) = {slope:.3f} * x + {intercept:.3f}\",\n",
    "        showarrow=False,\n",
    "        font=dict(\n",
    "            size=8\n",
    "        ),\n",
    "        xshift=-25\n",
    "    )\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(title_text=\"Linear Regression Analysis\", title_x=0.5)\n",
    "    fig.show()\n",
    "\n",
    "def subplot_1(fig, df, monthly_forecast_df, factor):\n",
    "\n",
    "    # historical data\n",
    "    fig.add_trace(go.Scatter(x=df.index, y=df[\"Portfolio\"], mode='lines', name='Portfolio', line=dict(color='royalblue')), secondary_y=False)\n",
    "    fig.add_trace(go.Scatter(x=df.index, y=df[\"S&P500\"], mode='lines', name='S&P500', line=dict(color='grey')), secondary_y=False)\n",
    "    fig.add_trace(go.Scatter(x=df.index, y=df[factor], mode='lines', name=factor, line=dict(dash='dot', color='red')), secondary_y=True)\n",
    "    \n",
    "    #fig.add_trace(go.Scatter(x=monthly_forecast_df.index, y=monthly_forecast_df[\"Portfolio\"], mode='lines', name='Portfolio Forecast', line=dict(color='orange')), secondary_y=False)\n",
    "    #fig.add_trace(go.Scatter(x=monthly_forecast_df.index, y=monthly_forecast_df[factor], mode='lines', name=f'{factor} Forecast', line=dict(color='green')), secondary_y=True)\n",
    "    #fig.add_shape(type=\"line\", x0=df.index[-1], x1=monthly_forecast_df.index[0], y0=0, y1=1, yref=\"paper\", line=dict(color=\"Black\", dash=\"dashdot\"))\n",
    "    fig.update_yaxes(title_text=\"Returns\")\n",
    "    fig.update_yaxes(title_text=factor, secondary_y=True)\n",
    "    return fig\n",
    "\n",
    "def subplot_2(fig, cumulative_forecast_df, factor):\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=cumulative_forecast_df.index, y=cumulative_forecast_df['Portfolio'], mode='lines', name='Cumulative Portfolio Returns', line=dict(color='purple')), row=1, col=3, secondary_y=False)\n",
    "    fig.add_trace(go.Scatter(x=cumulative_forecast_df.index, y=cumulative_forecast_df[factor], mode='lines', name=f'Cumulative {factor}', line=dict(color='cyan')), row=1, col=3, secondary_y=True)\n",
    "    fig.update_yaxes(title_text=\"Cumulative Returns\")\n",
    "    fig.update_yaxes(title_text=f\"Cumulative {factor}\", secondary_y=True)\n",
    "    return fig\n",
    "\n",
    "def subplot_3(fig, y, predictions):\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x = y,\n",
    "            y = predictions,\n",
    "            mode = 'markers',\n",
    "            marker=dict(\n",
    "                size=10,\n",
    "                color='rgba(152, 0, 0, .8)'\n",
    "            ),\n",
    "            name='Predicted vs Actual'\n",
    "        ), row=1, col=5, secondary_y=False\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "def subplot_4(fig, predictions, residuals):\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x = predictions,\n",
    "            y = residuals,\n",
    "            mode = 'markers',\n",
    "            marker=dict(\n",
    "                size=10,\n",
    "                color='rgba(152, 0, 0, .8)'\n",
    "            ),\n",
    "            name='Residuals'\n",
    "        ), row=2, col=5, secondary_y=False\n",
    "    )\n",
    "    fig.add_shape(\n",
    "        type='line',\n",
    "        line=dict(\n",
    "            color='grey',\n",
    "            width=2,\n",
    "            dash='dash'),\n",
    "        x0=min(predictions),\n",
    "        x1=max(predictions),\n",
    "        y0=0,\n",
    "        y1=0\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "def create_linear_regression_plots(df, factor, linear_regression_model, factor_forecast_model, months_to_forecast):\n",
    "    # Create fig object\n",
    "    fig = sp.make_subplots(rows=2, cols=5, specs=[[{'rowspan': 2, 'colspan': 2, 'secondary_y': True}, None, {'rowspan': 2, 'colspan': 2, 'secondary_y': True}, None, {}], [None, None, None, None, {}]])\n",
    "\n",
    "    X = df[[factor]]\n",
    "    y = df['Portfolio']\n",
    "    X2 = add_constant(X)\n",
    "    predictions = linear_regression_model.predict(X2)\n",
    "    residuals = y - predictions\n",
    "\n",
    "    intercept = linear_regression_model.params['const']\n",
    "    slope = linear_regression_model.params[factor]\n",
    "    \n",
    "    monthly_forecast_df, cumulative_forecast_df = forecast_portfolio_from_regression_based_on_predicted_factor(factor, linear_regression_model, factor_forecast_model, months_to_forecast)\n",
    "\n",
    "    # Pass fig into each subplot function\n",
    "    fig = subplot_1(fig, df, monthly_forecast_df, factor)\n",
    "    fig = subplot_2(fig, cumulative_forecast_df, factor)\n",
    "    fig = subplot_3(fig, y, predictions)\n",
    "    fig = subplot_4(fig, predictions, residuals)\n",
    "    \n",
    "    fig.update_layout(title_text=\"Linear Regression Analysis\", title_x=0.5)\n",
    "    fig.show()\n",
    "\n",
    "def run_model(returns_data, cumulative_returns_data, hyper_params_dict, months_to_forecast):\n",
    "    input_data_df = prepare_data(returns_data)\n",
    "    factor_list = get_factor_list(input_data_df)\n",
    "    print(f'reg_data input_data_df: {input_data_df.keys()}')\n",
    "    print(f'Regression data:\\n{input_data_df.head()}')\n",
    "\n",
    "    # Initialize dict to store models\n",
    "    regression_models_dict = {}\n",
    "    forecast_models_dict = {}\n",
    "\n",
    "    # Loop through all macro factors and build a regression model for each\n",
    "    for factor in factor_list:\n",
    "        # Create a dataframe for the current factor and the portfolio returns\n",
    "        df_factor = input_data_df[['Portfolio', factor]].dropna()\n",
    "        #print(f'creating linear regression model for *{factor}* data:\\n{df_factor.head()}')\n",
    "\n",
    "        # Calculate linear regression models for each factor\n",
    "        regression_model, coefficient, p_value = calculate_linear_regression_model_for_factor(df_factor, factor)\n",
    "\n",
    "        # Store the models, coefficients, and p-values in the dict\n",
    "        regression_models_dict[factor] = {\"model\": regression_model, \"coefficient\": coefficient, \"p_value\": p_value}\n",
    "\n",
    "        factor_forecast_model, factor_forecast = build_prophet_forecast_for_factor(df_factor.drop(['Portfolio'], axis=1), periods=months_to_forecast, data_frequency='MS', hyperparameters=hyper_params_dict[factor]['Monthly Change']['smape'])\n",
    "\n",
    "        # Store the forecast models and forecasts in the dict\n",
    "        forecast_models_dict[factor] = {\"model\": factor_forecast_model, \"forecast\": factor_forecast}\n",
    "        \n",
    "        create_linear_regression_plots_v0(input_data_df, factor, regression_model, factor_forecast_model, months_to_forecast)\n",
    "\n",
    "    plot_linear_regression_results(regression_models_dict)\n",
    "    # Use the multivariate model to identify significant factors\n",
    "    multivariate_model, significant_features = calculate_multivariate_analysis(input_data_df)\n",
    "    plot_multivariate_results(input_data_df, multivariate_model, significant_features)\n",
    "    \n",
    "    # Build the final Prophet model using the significant factors as regressors\n",
    "    #final_model, final_forecast = build_prophet_model_for_portfolio(input_data_df, significant_features, forecast_models_dict, months_to_forecast)\n",
    "    #plot_prophet_forecast(final_forecast)\n",
    "    \n",
    "    # Backtest the model\n",
    "    #mse, mae, forecast, holdout = backtest_model(input_data_df.reset_index().rename(columns={'index': 'ds', 'Portfolio': 'y'}), int(len(input_data_df)*0.8), final_model)\n",
    "    #plot_backtesting_results(mse, mae, forecast, holdout)\n",
    "\n",
    "    return regression_models_dict, forecast_models_dict #, final_model, final_forecast\n",
    "\n",
    "\n",
    "regression_models_dict, forecast_models_dict = run_model(returns_data, cumulative_returns_data, cur_tuned_params_dict, months_to_forecast=12*10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_regression_formula(model, factor_name, y):\n",
    "    # Get the intercept and coefficient\n",
    "    intercept = model.intercept_\n",
    "    coef = model.coef_[0]\n",
    "\n",
    "    # Format the formula string\n",
    "    formula = f\"{y} = {intercept:.4f} + ({coef:.4f} * {factor_name})\"\n",
    "\n",
    "    # Display the formula\n",
    "    print(formula)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
