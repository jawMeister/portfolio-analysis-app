{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "# enable absolute paths transversal (from notebooks folder to src folder)\n",
    "parent_dir = os.path.abspath('..')\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "    \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "print(os.environ.get('FRED_API_KEY'))\n",
    "print(os.environ.get('FMP_API_KEY'))\n",
    "print(os.environ.get('NASDAQ_API_KEY'))\n",
    "\n",
    "import quandl\n",
    "\n",
    "def resample_from_monthly_factor_series(series):\n",
    "    monthly_mean = series.resample('MS').mean()  \n",
    "    monthly_change = monthly_mean.pct_change()\n",
    "    quarterly_mean = series.resample('QS').mean()  \n",
    "    quarterly_change = quarterly_mean.pct_change()\n",
    "    yearly_mean = series.resample('YS').mean()  \n",
    "    yearly_change = yearly_mean.pct_change()\n",
    "    \n",
    "    return {\n",
    "        'Monthly': monthly_mean, \n",
    "        'Monthly Change': monthly_change, \n",
    "        'Quarterly': quarterly_mean, \n",
    "        'Quarterly Change': quarterly_change, \n",
    "        'Yearly': yearly_mean, \n",
    "        'Yearly Change': yearly_change\n",
    "    }\n",
    "\n",
    "\n",
    "us_m2_data = quandl.get(\"FED/M2_N_M\", authtoken=os.environ.get('NASDAQ_API_KEY'))\n",
    "print(f'head: {us_m2_data.head()}')\n",
    "print(f'tail: {us_m2_data.tail()}')\n",
    "print(f'description: {us_m2_data.describe()}')\n",
    "    \n",
    "us_m2_data = us_m2_data.shift(1, freq='D')  # shift the index by 1 day to align with FRED data reporting\n",
    "print(f'head: {us_m2_data.head()}')\n",
    "print(f'tail: {us_m2_data.tail()}')\n",
    "print(f'description: {us_m2_data.describe()}')\n",
    "\n",
    "us_m2_dict = resample_from_monthly_factor_series(us_m2_data['Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "# enable absolute paths transversal (from notebooks folder to src folder)\n",
    "parent_dir = os.path.abspath('..')\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "    \n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "from fredapi import Fred\n",
    "\n",
    "def resample_from_monthly_factor_series(series):\n",
    "    monthly_mean = series.resample('MS').mean()  \n",
    "    monthly_change = monthly_mean.pct_change()\n",
    "    quarterly_mean = series.resample('QS').mean()  \n",
    "    quarterly_change = quarterly_mean.pct_change()\n",
    "    yearly_mean = series.resample('YS').mean()  \n",
    "    yearly_change = yearly_mean.pct_change()\n",
    "    \n",
    "    return {\n",
    "        'Monthly': monthly_mean, \n",
    "        'Monthly Change': monthly_change, \n",
    "        'Quarterly': quarterly_mean, \n",
    "        'Quarterly Change': quarterly_change, \n",
    "        'Yearly': yearly_mean, \n",
    "        'Yearly Change': yearly_change\n",
    "    }\n",
    "\n",
    "def resample_from_quarterly_factor_series(series):\n",
    "    quarterly_mean = series.resample('QS').mean()\n",
    "    quarterly_change = quarterly_mean.pct_change()\n",
    "    yearly_mean = series.resample('YS').mean()\n",
    "    yearly_change = yearly_mean.pct_change()\n",
    "    \n",
    "    return {\n",
    "        'Quarterly': quarterly_mean, \n",
    "        'Quarterly Change': quarterly_change, \n",
    "        'Yearly': yearly_mean, \n",
    "        'Yearly Change': yearly_change\n",
    "    }\n",
    "\n",
    "def get_historical_macro_data(start_date, end_date):\n",
    "    rate_series = ['FEDFUNDS', 'T5YIFR']\n",
    "    monthly_series_names = {\n",
    "        'FEDFUNDS': 'Federal Funds Rate',\n",
    "        'UNRATE': 'Unemployment Rate',\n",
    "        'CPIAUCSL': 'CPI',\n",
    "        'PCE': 'PCE',\n",
    "        'RSAFS': 'Retail Sales',\n",
    "        'ICSA': 'Initial Claims',\n",
    "        'HOUST': 'Housing Starts',\n",
    "        'T5YIFR': '5-Year Forward Inflation Expectation Rate',\n",
    "        'USEPUINDXD': 'Economic Policy Uncertainty Index for United States',\n",
    "        'GS10': '10-Year Treasury Constant Maturity Rate'\n",
    "    }\n",
    "\n",
    "    quarterly_series_names = {\n",
    "        'GDPC1': 'GDP',\n",
    "    }\n",
    "\n",
    "    fred = Fred(api_key=os.environ.get('FRED_API_KEY'))\n",
    "    \n",
    "    macro_data_dict = {}\n",
    "    for series_code, series_name in monthly_series_names.items():\n",
    "        series = fred.get_series(series_code, start_date, end_date)\n",
    "        \n",
    "        if series_code in rate_series:\n",
    "            series = series / 100  # convert from decimal to percentage\n",
    "\n",
    "        macro_data_dict[series_name] = resample_from_monthly_factor_series(series)\n",
    "\n",
    "    for series_code, series_name in quarterly_series_names.items():\n",
    "        series = fred.get_series(series_code, start_date, end_date)\n",
    "\n",
    "        macro_data_dict[series_name] = resample_from_quarterly_factor_series(series)\n",
    "\n",
    "    us_m2_money_supply_base = quandl.get(\"FED/M2_N_M\", authtoken=os.environ.get('NASDAQ_API_KEY'), start_date=start_date, end_date=end_date)\n",
    "    us_m2_money_supply_base = us_m2_money_supply_base.shift(1, freq='D')  # shift the index by 1 day to align with FRED data reporting\n",
    "\n",
    "    macro_data_dict['US M2 Money Supply'] = resample_from_monthly_factor_series(us_m2_money_supply_base['Value'])\n",
    "\n",
    "    return macro_data_dict\n",
    "\n",
    "\n",
    "start_date = '2014-01-01'\n",
    "end_date = datetime.now() - timedelta(1)\n",
    "\n",
    "# get the data\n",
    "macro_data_dict = get_historical_macro_data(start_date, end_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the raw data\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "def plot_historical_macro_data(factor, time_basis, time_series):\n",
    "    plots = []\n",
    "\n",
    "    fig = go.Figure()\n",
    "    # Add macroeconomic factor trace\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=time_series.index, y=time_series, mode='lines', name=factor))\n",
    "\n",
    "    if 'Change' in factor or 'Rate' in factor:            \n",
    "        fig.update_layout(\n",
    "            title=f'{factor} Historical Data<br><sup>({time_basis})</sup>',\n",
    "            yaxis_tickformat='.1%'\n",
    "        )\n",
    "    else:\n",
    "        # TODO: need a lookup by factor for what the units are on the y-axis\n",
    "        fig.update_layout(\n",
    "            title=f'{factor} Historical Data<br><sup>({time_basis})</sup>',\n",
    "        )\n",
    "\n",
    "    return fig\n",
    "\n",
    "for factor in macro_data_dict.keys():\n",
    "    print(f'plotting {factor} data')\n",
    "    for time_basis in macro_data_dict[factor].keys():\n",
    "        fig = plot_historical_macro_data(factor, time_basis, macro_data_dict[factor][time_basis])\n",
    "        fig.show()\n",
    "        \n",
    "print('*** done plotting raw data ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_data_dict['PCE']['Monthly'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n",
    "\n",
    "# Define the desired order of series\n",
    "series_order = ['Monthly', 'Monthly Change', 'Quarterly', 'Quarterly Change', 'Yearly', 'Yearly Change']\n",
    "\n",
    "charts = []  # a list to hold the charts for each factor\n",
    "\n",
    "for factor, data_dict in macro_data_dict.items():\n",
    "    # Combine all series for a single factor into a DataFrame for plotting\n",
    "    factor_df = pd.DataFrame()\n",
    "\n",
    "    # Sort series according to the desired order\n",
    "    ordered_data_dict = {key: data_dict[key] for key in series_order if key in data_dict}\n",
    "\n",
    "    for series_name, series in ordered_data_dict.items():\n",
    "        temp_df = pd.DataFrame(series)\n",
    "        temp_df = temp_df.reset_index()\n",
    "        temp_df.columns = ['Date', 'Value']\n",
    "        temp_df['Series'] = series_name\n",
    "        factor_df = pd.concat([factor_df, temp_df], axis=0)\n",
    "\n",
    "    # Create a chart for the factor and add it to the list\n",
    "    chart = alt.Chart(factor_df, title=factor).mark_line().encode(\n",
    "        x='Date:T',\n",
    "        y=alt.Y('Value:Q', scale=alt.Scale(zero=False)),\n",
    "        facet=alt.Facet('Series:N', columns=len(ordered_data_dict))\n",
    "    ).properties(\n",
    "        width=200,\n",
    "        height=200\n",
    "    ).resolve_scale(\n",
    "        y='independent'\n",
    "    )\n",
    "\n",
    "    charts.append(chart)\n",
    "\n",
    "# Combine the charts vertically\n",
    "final_chart = alt.vconcat(*charts, spacing=20)\n",
    "\n",
    "final_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "\n",
    "from fredapi import Fred\n",
    "import quandl\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# disable prophet logging\n",
    "import logging\n",
    "logging.getLogger('prophet').setLevel(logging.WARNING)\n",
    "logging.getLogger(\"cmdstanpy\").disabled=True\n",
    "\n",
    "\n",
    "def tune_hyperparameters(df, initial, period, horizon):\n",
    "    print(f'initial_window_in_days: {initial}, period_in_days: {period}, horizon_in_days: {horizon}')\n",
    "    print(f'df.shape: {df.shape}\\ndf.head():\\n{df.head()}')\n",
    "    \n",
    "    param_grid = {  \n",
    "        'changepoint_prior_scale': [0.001, 0.005, 0.01, 0.05, 0.1, 0.25, 0.5],\n",
    "        'seasonality_prior_scale': [0.01, 0.1, 1.0, 5.0, 10.0],\n",
    "        'seasonality_mode': ['additive', 'multiplicative'],\n",
    "    }\n",
    "    # Generate all combinations of parameters\n",
    "    all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "    \n",
    "    # Generate all combinations of parameters\n",
    "    all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "    rmses = []  # Store the RMSEs for each params here\n",
    "    smapes = []  # Store the sMAPEs for each params here\n",
    "    coverages = []  # Store the Coverages for each params here\n",
    "    \n",
    "    # Use cross validation to evaluate all parameters\n",
    "    for params in all_params:\n",
    "        m = Prophet(**params).fit(df)  # Fit model with given params\n",
    "        df_cv = cross_validation(m, initial=f'{initial} days', period=f'{period} days', horizon=f'{horizon} days', parallel=\"processes\")\n",
    "        df_p = performance_metrics(df_cv, rolling_window=1)\n",
    "        rmses.append(df_p['rmse'].values[0])\n",
    "        smapes.append(df_p['smape'].values[0])\n",
    "        coverages.append(df_p['coverage'].values[0])\n",
    "\n",
    "    # Find the best parameters\n",
    "    best_params_rmse = all_params[np.argmin(rmses)]\n",
    "    best_params_smape = all_params[np.argmin(smapes)]\n",
    "    best_params_coverage = all_params[np.argmax(coverages)]\n",
    "\n",
    "    return best_params_rmse, best_params_smape, best_params_coverage\n",
    "\n",
    "# horizon = number of days to forecast - when only horizon is specified, prophet defaults initial to 3x horizon, period to be 1/2 horizon\n",
    "# initial = number of days to train on\n",
    "# period = number of days between training points - used to calculate cutoffs, default is 1/2 horizon\n",
    "def tune_hyperparameters_for_macro_factors(macro_data_dict, initial_window_in_days, period_in_days, horizon_in_days):\n",
    "    \n",
    "    # Define a DataFrame to store the tuned hyperparameters for each time series\n",
    "    # Set 'time_series_name' and 'macro_factor', e.g., Month over Month, CPI Monthly Change, as the index for easier lookup\n",
    "    rmse_optimized_df = pd.DataFrame(columns=['rating', 'time_basis', 'macro_factor', 'rmse', 'initial_window', 'period', 'horizon', 'changepoint_prior_scale', 'seasonality_prior_scale', 'seasonality_mode'])\n",
    "    smape_optimized_df = pd.DataFrame(columns=['rating', 'time_basis', 'macro_factor', 'mape', 'initial_window', 'period', 'horizon', 'changepoint_prior_scale', 'seasonality_prior_scale', 'seasonality_mode'])\n",
    "    coverage_optimized_df = pd.DataFrame(columns=['rating', 'time_basis', 'macro_factor', 'mape', 'initial_window', 'period', 'horizon', 'changepoint_prior_scale', 'seasonality_prior_scale', 'seasonality_mode'])\n",
    "        \n",
    "    # Loop over the time series data\n",
    "    for factor, time_bases in macro_data_dict.items():\n",
    "        for time_basis, time_series in time_bases.items():\n",
    "            \n",
    "            df = time_series.to_frame()\n",
    "            df.columns = ['y']\n",
    "            df['ds'] = df.index\n",
    "            df.dropna(inplace=True)\n",
    "            \n",
    "            # Tune hyperparameters\n",
    "            best_rmse, best_mape, best_coverage = tune_hyperparameters(df, initial_window_in_days, period_in_days, horizon_in_days)\n",
    "           \n",
    "            # Store the tuned hyperparameters - add a rating column for later analysis\n",
    "            rmse_optimized_df = rmse_optimized_df.append({'rating': \"n/a/\", 'time_basis': time_basis, 'macro_factor': factor, 'rmse': best_rmse, 'initial_window': initial_window_in_days, 'period': period_in_days, 'horizon': horizon_in_days, 'changepoint_prior_scale': best_rmse['changepoint_prior_scale'], 'seasonality_prior_scale': best_rmse['seasonality_prior_scale'], 'seasonality_mode': best_rmse['seasonality_mode']}, ignore_index=True)\n",
    "            smape_optimized_df = smape_optimized_df.append({'rating': \"n/a/\",'time_basis': time_basis, 'macro_factor': factor, 'mape': best_mape, 'initial_window': initial_window_in_days, 'period': period_in_days, 'horizon': horizon_in_days, 'changepoint_prior_scale': best_mape['changepoint_prior_scale'], 'seasonality_prior_scale': best_mape['seasonality_prior_scale'], 'seasonality_mode': best_mape['seasonality_mode']}, ignore_index=True)\n",
    "            coverage_optimized_df = coverage_optimized_df.append({'rating': \"n/a/\",'time_basis': time_basis, 'macro_factor': factor, 'mape': best_coverage, 'initial_window': initial_window_in_days, 'period': period_in_days, 'horizon': horizon_in_days, 'changepoint_prior_scale': best_coverage['changepoint_prior_scale'], 'seasonality_prior_scale': best_coverage['seasonality_prior_scale'], 'seasonality_mode': best_coverage['seasonality_mode']}, ignore_index=True)\n",
    "\n",
    "    rmse_optimized_df.set_index(['macro_factor','time_basis'], inplace=True)\n",
    "    smape_optimized_df.set_index(['macro_factor','time_basis'], inplace=True)\n",
    "    coverage_optimized_df.set_index(['macro_factor','time_basis'], inplace=True)\n",
    "    \n",
    "    return rmse_optimized_df, smape_optimized_df, coverage_optimized_df\n",
    "\n",
    "def save_tuned_hyperparameters(tuned_params_df, suffix=None):\n",
    "    # Save tuned hyperparameters to a csv file\n",
    "    date = datetime.now().strftime(\"%Y%m%d\")\n",
    "   # print(f'date: {date}')\n",
    "    \n",
    "    file_name = f'tuned_macro_hyperparameters_{suffix}_{date}'\n",
    "    \n",
    "    with open(file_name, 'w') as f:\n",
    "        tuned_params_df.to_csv(f)\n",
    "        \n",
    "    return\n",
    "\n",
    "def load_latest_tuned_hyperparameters():\n",
    "    # List all files that begin with \"tuned_macro_hyperparameters\"\n",
    "    files = glob.glob('tuned_macro_hyperparameters_*.csv')\n",
    "\n",
    "    # If no files found, return None\n",
    "    if not files:\n",
    "        return None\n",
    "\n",
    "    # Sort files by date\n",
    "    files.sort(key=os.path.getmtime, reverse=True)\n",
    "\n",
    "    # Load the most recent file\n",
    "    latest_file = files[0]\n",
    "    df = pd.read_csv(latest_file)\n",
    "\n",
    "    return df\n",
    "\n",
    "def load_tuned_hyperparameters(file_name):\n",
    "\n",
    "    df = pd.read_csv(file_name)\n",
    "\n",
    "    return df\n",
    "\n",
    "initial_window_in_days = 365*6\n",
    "horizon_in_days = 365 \n",
    "period_in_days = 180 \n",
    "\n",
    "# for month to month data, we want to forecast 1 month ahead and do that for N periods\n",
    "# for quarter to quarter data, we want to forecast 1 quarter ahead and do that for N periods\n",
    "# for year to year data, we want to forecast 1 year ahead and do that for N periods\n",
    "\n",
    "# initial window will impact training model\n",
    "\n",
    "rmse_optimized_df, smape_optimized_df, coverage_optimized_df = tune_hyperparameters_for_macro_factors(macro_data_dict, initial_window_in_days, period_in_days, horizon_in_days)\n",
    "\n",
    "suffix = f'rmse_init_{initial_window_in_days}_period_{period_in_days}_horizon_{horizon_in_days}'\n",
    "save_tuned_hyperparameters(rmse_optimized_df, suffix)\n",
    "\n",
    "suffix = f'coverage_init_{initial_window_in_days}_period_{period_in_days}_horizon_{horizon_in_days}'\n",
    "save_tuned_hyperparameters(coverage_optimized_df, suffix)\n",
    "\n",
    "suffix = f'smape_init_{initial_window_in_days}_period_{period_in_days}_horizon_{horizon_in_days}'\n",
    "save_tuned_hyperparameters(smape_optimized_df, suffix)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "macro_factor in ['US Money Supply', 'CPI', 'PCE', etc.]\n",
    "time_basis in ['Monthly', 'Monthly Change', 'Quarterly', 'Yearly', etc.]\n",
    "hyper_parameter_optimization_type in ['rmse', 'smape', 'coverage']\n",
    "hyper_parameters {\n",
    "    'changepoint_prior_scale': float, \n",
    "    'seasonality_prior_scale': float, \n",
    "    'seasonality_mode'in ['additive', 'multiplicative'],\n",
    "}\n",
    "\n",
    "hyper_parameter_dict = {}\n",
    "hyper_parameter_dict['CPI']['Quarterly'][rmse]['ranking']\n",
    "hyper_parameter_dict['CPI']['Quarterly'][rmse]['seasonality_prior_scale']\n",
    "\n",
    "{'macro_factor': {\n",
    "    'US Money Supply': {\n",
    "        'Monthly': {\n",
    "            'rmse':\n",
    "                {'ranking': str, 'changepoint_prior_scale': float, 'seasonality_prior_scale': float, 'seasonality_mode': 'multiplicative'},\n",
    "            'coverage':\n",
    "                {'ranking': str, 'changepoint_prior_scale': float, 'seasonality_prior_scale': float, 'seasonality_mode': 'multiplicative'},\n",
    "            },\n",
    "    'CPI': {\n",
    "        'Monthly': {\n",
    "            'rmse':\n",
    "                {'ranking': str, 'changepoint_prior_scale': float, 'seasonality_prior_scale': float, 'seasonality_mode': 'multiplicative'},\n",
    "            'coverage':\n",
    "                {'ranking': str, 'changepoint_prior_scale': float, 'seasonality_prior_scale': float, 'seasonality_mode': 'multiplicative'},\n",
    "            },\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "import json\n",
    "import glob\n",
    "\n",
    "# disable prophet logging\n",
    "import logging\n",
    "logging.getLogger('prophet').setLevel(logging.WARNING)\n",
    "logging.getLogger(\"cmdstanpy\").disabled=True\n",
    "\n",
    "\n",
    "def tune_hyperparameters(df, initial, period, horizon):\n",
    "    print(f'initial_window_in_days: {initial}, period_in_days: {period}, horizon_in_days: {horizon}')\n",
    "    print(f'df.shape: {df.shape}\\ndf.head():\\n{df.head()}')\n",
    "    \n",
    "    param_grid = {  \n",
    "        'changepoint_prior_scale': [0.001, 0.005, 0.01, 0.05, 0.1, 0.25, 0.5],\n",
    "        'seasonality_prior_scale': [0.01, 0.1, 1.0, 5.0, 10.0],\n",
    "        'seasonality_mode': ['additive', 'multiplicative'],\n",
    "    }\n",
    "    # Generate all combinations of parameters\n",
    "    all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "    \n",
    "    # Generate all combinations of parameters\n",
    "    all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "    rmses = []  # Store the RMSEs for each params here\n",
    "    smapes = []  # Store the sMAPEs for each params here\n",
    "    coverages = []  # Store the Coverages for each params here\n",
    "    \n",
    "    # Use cross validation to evaluate all parameters\n",
    "    for params in all_params:\n",
    "        m = Prophet(**params).fit(df)  # Fit model with given params\n",
    "        df_cv = cross_validation(m, initial=f'{initial} days', period=f'{period} days', horizon=f'{horizon} days', parallel=\"processes\")\n",
    "        df_p = performance_metrics(df_cv, rolling_window=1)\n",
    "        rmses.append(df_p['rmse'].values[0])\n",
    "        smapes.append(df_p['smape'].values[0])\n",
    "        coverages.append(df_p['coverage'].values[0])\n",
    "\n",
    "    # Find the best parameters\n",
    "    best_params_rmse = all_params[np.argmin(rmses)]\n",
    "    best_params_smape = all_params[np.argmin(smapes)]\n",
    "    best_params_coverage = all_params[np.argmax(coverages)]\n",
    "\n",
    "    return best_params_rmse, best_params_smape, best_params_coverage\n",
    "\n",
    "def tune_hyperparameters_for_macro_factors(macro_data_dict, initial_window_in_days, period_in_days, horizon_in_days):\n",
    "    # Dictionary to store the hyperparameters\n",
    "    hyper_parameter_dict = {}\n",
    "\n",
    "    # Loop over the time series data\n",
    "    for factor, time_bases in macro_data_dict.items():\n",
    "        hyper_parameter_dict[factor] = {}\n",
    "        for time_basis, time_series in time_bases.items():\n",
    "            hyper_parameter_dict[factor][time_basis] = {}\n",
    "            \n",
    "            df = time_series.to_frame()\n",
    "            df.columns = ['y']\n",
    "            df['ds'] = df.index\n",
    "            df.dropna(inplace=True)\n",
    "            \n",
    "            # Tune hyperparameters\n",
    "            best_rmse, best_mape, best_coverage = tune_hyperparameters(df, initial_window_in_days, period_in_days, horizon_in_days)\n",
    "           \n",
    "            # Store the tuned hyperparameters\n",
    "            hyper_parameter_dict[factor][time_basis]['rmse'] = {'rating': 'n/a', **best_rmse}\n",
    "            hyper_parameter_dict[factor][time_basis]['smape'] = {'rating': 'n/a', **best_mape}\n",
    "            hyper_parameter_dict[factor][time_basis]['coverage'] = {'rating': 'n/a', **best_coverage}\n",
    "    \n",
    "    return hyper_parameter_dict\n",
    "\n",
    "def save_tuned_hyperparameters(hyper_parameter_dict, suffix=None):\n",
    "    # Save hyperparameters to a json file\n",
    "    date = datetime.now().strftime(\"%Y%m%d\")\n",
    "    \n",
    "    file_name = f'tuned_macro_hyperparameters_{suffix}_{date}.json'\n",
    "    \n",
    "    with open(file_name, 'w') as f:\n",
    "        json.dump(hyper_parameter_dict, f)\n",
    "        \n",
    "    return\n",
    "\n",
    "def load_latest_tuned_hyperparameters():\n",
    "    # List all files that begin with \"tuned_macro_hyperparameters\"\n",
    "    files = glob.glob('tuned_macro_hyperparameters_*.json')\n",
    "\n",
    "    # If no files found, return None\n",
    "    if not files:\n",
    "        return None\n",
    "\n",
    "    # Sort files by date\n",
    "    files.sort(key=os.path.getmtime, reverse=True)\n",
    "\n",
    "    # Load the most recent file\n",
    "    latest_file = files[0]\n",
    "    with open(latest_file, 'r') as f:\n",
    "        hyper_parameter_dict = json.load(f)\n",
    "\n",
    "    return hyper_parameter_dict\n",
    "\n",
    "def load_tuned_hyperparameters(file_name):\n",
    "    with open(file_name, 'r') as f:\n",
    "        hyper_parameter_dict = json.load(f)\n",
    "\n",
    "    return hyper_parameter_dict\n",
    "\n",
    "initial_window_in_days = 365*6\n",
    "horizon_in_days = 365 \n",
    "period_in_days = 180 \n",
    "\n",
    "# for month to month data, we want to forecast 1 month ahead and do that for N periods\n",
    "# for quarter to quarter data, we want to forecast 1 quarter ahead and do that for N periods\n",
    "# for year to year data, we want to forecast 1 year ahead and do that for N periods\n",
    "\n",
    "# initial window will impact training model\n",
    "\n",
    "for initial_window_in_days in [365*6, 365*4, 365*3, 365*2, 365]:\n",
    "    for horizon_in_days in [initial_window_in_days * 0.5, initial_window_in_days * 0.25, initial_window_in_days * 0.125, initial_window_in_days * 0.0625, initial_window_in_days * 0.03125]:\n",
    "        for period_in_days in [horizon_in_days, horizon_in_days*0.5]:\n",
    "            print(f'initial_window_in_days: {initial_window_in_days}, period_in_days: {period_in_days}, horizon_in_days: {horizon_in_days}')\n",
    "            # Tune hyperparameters for macro factors\n",
    "            hyper_parameter_dict = tune_hyperparameters_for_macro_factors(macro_data_dict, initial_window_in_days, period_in_days, horizon_in_days)\n",
    "\n",
    "            suffix = f'tuned_hyper_parms_w_init_{initial_window_in_days}_period_{period_in_days}_horizon_{horizon_in_days}'\n",
    "            save_tuned_hyperparameters(hyper_parameter_dict, suffix)\n",
    "            \n",
    "#hyper_parameter_dict = tune_hyperparameters_for_macro_factors(macro_data_dict, initial_window_in_days, period_in_days, horizon_in_days)\n",
    "\n",
    "#suffix = f'tuned_hyper_parms_w_init_{initial_window_in_days}_period_{period_in_days}_horizon_{horizon_in_days}'\n",
    "#save_tuned_hyperparameters(hyper_parameter_dict, suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "\n",
    "from prophet.plot import plot_plotly\n",
    "import plotly.graph_objs as go\n",
    "    \n",
    "import glob\n",
    "\n",
    "# Define the forecast function\n",
    "def prophet_forecast(df, periods, data_frequency, hyperparameters):\n",
    "    \n",
    "    print(f'prophet_forecast df:\\n{df.head()}')\n",
    "    \n",
    "    # Check for missing values\n",
    "    if df['y'].isna().any():\n",
    "        print(\"WARNING: The 'y' column contains missing values. These will be dropped.\")\n",
    "        df = df.dropna()\n",
    "\n",
    "    # Check for non-numeric values\n",
    "    if df['y'].apply(lambda x: not isinstance(x, (int, float))).any():\n",
    "        print(\"WARNING: The 'y' column contains non-numeric values. These cannot be used in the model.\")\n",
    "    \n",
    "    # Check for zero values\n",
    "    if (df['y'] == 0).any():\n",
    "        print(\"WARNING: The 'y' column contains zero values. These can cause problems for the model.\")\n",
    "    \n",
    "    # Check for extreme values\n",
    "    if df['y'].max() > 1e6 or df['y'].min() < -1e6:\n",
    "        print(\"WARNING: The 'y' column contains very large or very small values. These can cause problems for the model.\")\n",
    "\n",
    "    # define the model\n",
    "    model = Prophet(**hyperparameters)\n",
    "    \n",
    "    # TODO: for our portfolio forecast, add regressors for each macro factor?\n",
    "    # model.add_regressor('additional_regressor')\n",
    "    \n",
    "    # fit the model\n",
    "    model.fit(df)\n",
    "    \n",
    "    # define the period for which we want a prediction - most data is monthly, use MS for month start\n",
    "    future = model.make_future_dataframe(periods=periods, freq=data_frequency)\n",
    "    \n",
    "    # use the model to make a forecast\n",
    "    forecast = model.predict(future)\n",
    "    \n",
    "    return df, model, forecast\n",
    "\n",
    "def plot_historical_macro_data_with_forecast(series, forecast, time_series_name, factor_name):\n",
    "    \n",
    "    print(f'plot_historical_macro_data_with_forecast {time_series_name} series with factor {factor_name}:\\n{series.head()}')\n",
    "    print(f'plot_historical_macro_data_with_forecast forecast {time_series_name} series with factor {factor_name}:\\n{forecast.head()}')\n",
    "    \n",
    "    \n",
    "    # Prophet plot\n",
    "    fig1 = plot_plotly(model, forecast)\n",
    "    fig1.update_layout(title=f'{factor_name} Forecast by Prophet')\n",
    "    \n",
    "    \n",
    "    # Your custom plot\n",
    "    fig2 = go.Figure()\n",
    "    \n",
    "    # Add macroeconomic factor trace\n",
    "    fig2.add_trace(go.Scatter(x=series.index, y=series['y'], mode='lines', name='Historical'))\n",
    "\n",
    "    # Add forecasted macroeconomic factor trace\n",
    "    fig2.add_trace(go.Scatter(x=forecast['ds'], y=forecast['yhat'], mode='lines', name='Forecast', line=dict(color='red', width=2, dash='dot')))\n",
    "\n",
    "    # Add confidence interval\n",
    "    fig2.add_trace(go.Scatter(x=forecast['ds'], y=forecast['yhat_lower'], fill=None, mode='lines', line_color='gray', name='Lower Bound'))\n",
    "    fig2.add_trace(go.Scatter(x=forecast['ds'], y=forecast['yhat_upper'], fill='tonexty', mode='lines', line_color='gray', name='Upper Bound'))\n",
    "\n",
    "    # Set axis titles\n",
    "    fig2.update_yaxes(title_text='Value')\n",
    "    \n",
    "    fig2.update_layout(title_text=f'{factor_name} Historical Data with Forecast<br><sup>({time_series_name})</sup>')\n",
    "    \n",
    "    return fig1, fig2\n",
    "\n",
    "initial_window_in_days = 365*6\n",
    "horizon_in_days = 365 # 6 month forecast horizon\n",
    "period_in_days = 180 # quarterly training period\n",
    "\n",
    "# for month to month data, we want to forecast 1 month ahead and do that for N periods\n",
    "# for quarter to quarter data, we want to forecast 1 quarter ahead and do that for N periods\n",
    "# for year to year data, we want to forecast 1 year ahead and do that for N periods\n",
    "\n",
    "def load_latest_tuned_hyperparameters():\n",
    "    # List all files that begin with \"tuned_macro_hyperparameters\"\n",
    "    files = glob.glob('tuned_macro_hyperparameters_*.csv')\n",
    "\n",
    "    # If no files found, return None\n",
    "    if not files:\n",
    "        return None\n",
    "\n",
    "    # Sort files by date\n",
    "    files.sort(key=os.path.getmtime, reverse=True)\n",
    "\n",
    "    # Load the most recent file\n",
    "    latest_file = files[0]\n",
    "    df = pd.read_csv(latest_file)\n",
    "\n",
    "    return df\n",
    "\n",
    "cur_tuned_params_df = load_latest_tuned_hyperparameters()\n",
    "\n",
    "years_to_forecast = 10\n",
    "figs = []\n",
    "for factor, time_bases in macro_data_dict.items():\n",
    "    for time_basis, series in time_bases.items():\n",
    "        \n",
    "        print(f'Forecasting {factor} from {time_basis} data for series:\\n{series.head()}\\ndescription:\\n{series.describe()}')\n",
    "        # Get tuned parameters for this time series\n",
    "        hyperparameters = cur_tuned_params_df.loc[(time_basis, factor)].to_dict()\n",
    "        print(f'{factor} from {time_basis} leveraging these hyperparameters:\\n{hyperparameters}')\n",
    "        \n",
    "        df = series.to_frame()\n",
    "        df.columns = ['y']\n",
    "        df['ds'] = df.index\n",
    "        \n",
    "        if 'Month' in time_basis:\n",
    "            data_frequency = 'MS'\n",
    "            periods = years_to_forecast * 12 # 12 months per year\n",
    "        elif 'Quarter' in time_basis:\n",
    "            data_frequency = 'QS'\n",
    "            periods = years_to_forecast * 4 # 4 quarters per year\n",
    "        elif 'Year' in time_basis:\n",
    "            data_frequency = 'YS'\n",
    "            periods = years_to_forecast\n",
    "        else:\n",
    "            data_frequency = None\n",
    "            periods = 365\n",
    "             \n",
    "        #horizon = calculate_horizon(df)\n",
    "        df, model, forecast = prophet_forecast(df, periods, data_frequency, hyperparameters)\n",
    "\n",
    "        fig2 = plot_historical_macro_data_with_forecast(df, forecast, time_basis, factor)\n",
    "        \n",
    "        # Prophet plot\n",
    "        fig1 = plot_plotly(model, forecast)\n",
    "        fig1.update_layout(title=f'{factor} Forecast by Prophet')\n",
    "    \n",
    "        fig1.show()\n",
    "        fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
